// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// RUN: %clang_cc1 -triple x86_64 -emit-llvm %s \
// RUN:   -o - | FileCheck -check-prefixes=CHECK,NATIVE %s
// RUN: %clang_cc1 -triple riscv32 -target-feature -a -emit-llvm %s \
// RUN:   -o - | FileCheck -check-prefixes=CHECK,LIBCALL %s

// NATIVE-LABEL: define dso_local void @foo(
// NATIVE-SAME: i32 noundef [[X:%.*]]) #[[ATTR0:[0-9]+]] {
// NATIVE-NEXT:  [[ENTRY:.*]]:
// NATIVE-NEXT:    [[X_ADDR:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[I:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[J:%.*]] = alloca i16, align 2
// NATIVE-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP6:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP7:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP8:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP19:%.*]] = alloca i16, align 2
// NATIVE-NEXT:    [[ATOMIC_TEMP20:%.*]] = alloca i16, align 2
// NATIVE-NEXT:    [[ATOMIC_TEMP21:%.*]] = alloca i16, align 2
// NATIVE-NEXT:    store i32 [[X]], ptr [[X_ADDR]], align 4
// NATIVE-NEXT:    store i32 0, ptr [[I]], align 4
// NATIVE-NEXT:    store i16 0, ptr [[J]], align 2
// NATIVE-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i32, ptr [[I]] seq_cst, align 4
// NATIVE-NEXT:    br label %[[ATOMIC_OP:.*]]
// NATIVE:       [[ATOMIC_OP]]:
// NATIVE-NEXT:    [[TMP0:%.*]] = phi i32 [ [[ATOMIC_LOAD]], %[[ENTRY]] ], [ [[TMP1:%.*]], %[[ATOMIC_OP]] ]
// NATIVE-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP0]], 2
// NATIVE-NEXT:    store i32 [[TMP0]], ptr [[ATOMIC_TEMP]], align 4
// NATIVE-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP1]], align 4
// NATIVE-NEXT:    [[CMPXCHG_EXPECTED:%.*]] = load i32, ptr [[ATOMIC_TEMP]], align 4
// NATIVE-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i32, ptr [[ATOMIC_TEMP1]], align 4
// NATIVE-NEXT:    [[CMPXCHG_PAIR:%.*]] = cmpxchg ptr [[I]], i32 [[CMPXCHG_EXPECTED]], i32 [[CMPXCHG_DESIRED]] seq_cst seq_cst, align 4
// NATIVE-NEXT:    [[CMPXCHG_PREV:%.*]] = extractvalue { i32, i1 } [[CMPXCHG_PAIR]], 0
// NATIVE-NEXT:    store i32 [[CMPXCHG_PREV]], ptr [[ATOMIC_TEMP2]], align 4
// NATIVE-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = extractvalue { i32, i1 } [[CMPXCHG_PAIR]], 1
// NATIVE-NEXT:    [[TMP1]] = load i32, ptr [[ATOMIC_TEMP2]], align 4
// NATIVE-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// NATIVE:       [[ATOMIC_CONT]]:
// NATIVE-NEXT:    [[ATOMIC_LOAD4:%.*]] = load atomic i32, ptr [[I]] seq_cst, align 4
// NATIVE-NEXT:    br label %[[ATOMIC_OP3:.*]]
// NATIVE:       [[ATOMIC_OP3]]:
// NATIVE-NEXT:    [[TMP2:%.*]] = phi i32 [ [[ATOMIC_LOAD4]], %[[ATOMIC_CONT]] ], [ [[TMP3:%.*]], %[[ATOMIC_OP3]] ]
// NATIVE-NEXT:    [[DIV:%.*]] = sdiv i32 [[TMP2]], 2
// NATIVE-NEXT:    store i32 [[TMP2]], ptr [[ATOMIC_TEMP6]], align 4
// NATIVE-NEXT:    store i32 [[DIV]], ptr [[ATOMIC_TEMP7]], align 4
// NATIVE-NEXT:    [[CMPXCHG_EXPECTED9:%.*]] = load i32, ptr [[ATOMIC_TEMP6]], align 4
// NATIVE-NEXT:    [[CMPXCHG_DESIRED10:%.*]] = load i32, ptr [[ATOMIC_TEMP7]], align 4
// NATIVE-NEXT:    [[CMPXCHG_PAIR11:%.*]] = cmpxchg ptr [[I]], i32 [[CMPXCHG_EXPECTED9]], i32 [[CMPXCHG_DESIRED10]] seq_cst seq_cst, align 4
// NATIVE-NEXT:    [[CMPXCHG_PREV12:%.*]] = extractvalue { i32, i1 } [[CMPXCHG_PAIR11]], 0
// NATIVE-NEXT:    store i32 [[CMPXCHG_PREV12]], ptr [[ATOMIC_TEMP8]], align 4
// NATIVE-NEXT:    [[CMPXCHG_SUCCESS13:%.*]] = extractvalue { i32, i1 } [[CMPXCHG_PAIR11]], 1
// NATIVE-NEXT:    [[TMP3]] = load i32, ptr [[ATOMIC_TEMP8]], align 4
// NATIVE-NEXT:    br i1 [[CMPXCHG_SUCCESS13]], label %[[ATOMIC_CONT5:.*]], label %[[ATOMIC_OP3]]
// NATIVE:       [[ATOMIC_CONT5]]:
// NATIVE-NEXT:    [[TMP4:%.*]] = load i32, ptr [[X_ADDR]], align 4
// NATIVE-NEXT:    [[ATOMIC_LOAD15:%.*]] = load atomic i16, ptr [[J]] seq_cst, align 2
// NATIVE-NEXT:    br label %[[ATOMIC_OP14:.*]]
// NATIVE:       [[ATOMIC_OP14]]:
// NATIVE-NEXT:    [[TMP5:%.*]] = phi i16 [ [[ATOMIC_LOAD15]], %[[ATOMIC_CONT5]] ], [ [[TMP6:%.*]], %[[ATOMIC_OP14]] ]
// NATIVE-NEXT:    [[CONV:%.*]] = zext i16 [[TMP5]] to i32
// NATIVE-NEXT:    [[DIV16:%.*]] = sdiv i32 [[CONV]], [[TMP4]]
// NATIVE-NEXT:    [[CONV17:%.*]] = trunc i32 [[DIV16]] to i16
// NATIVE-NEXT:    store i16 [[TMP5]], ptr [[ATOMIC_TEMP19]], align 2
// NATIVE-NEXT:    store i16 [[CONV17]], ptr [[ATOMIC_TEMP20]], align 2
// NATIVE-NEXT:    [[CMPXCHG_EXPECTED22:%.*]] = load i16, ptr [[ATOMIC_TEMP19]], align 2
// NATIVE-NEXT:    [[CMPXCHG_DESIRED23:%.*]] = load i16, ptr [[ATOMIC_TEMP20]], align 2
// NATIVE-NEXT:    [[CMPXCHG_PAIR24:%.*]] = cmpxchg ptr [[J]], i16 [[CMPXCHG_EXPECTED22]], i16 [[CMPXCHG_DESIRED23]] seq_cst seq_cst, align 2
// NATIVE-NEXT:    [[CMPXCHG_PREV25:%.*]] = extractvalue { i16, i1 } [[CMPXCHG_PAIR24]], 0
// NATIVE-NEXT:    store i16 [[CMPXCHG_PREV25]], ptr [[ATOMIC_TEMP21]], align 2
// NATIVE-NEXT:    [[CMPXCHG_SUCCESS26:%.*]] = extractvalue { i16, i1 } [[CMPXCHG_PAIR24]], 1
// NATIVE-NEXT:    [[TMP6]] = load i16, ptr [[ATOMIC_TEMP21]], align 2
// NATIVE-NEXT:    br i1 [[CMPXCHG_SUCCESS26]], label %[[ATOMIC_CONT18:.*]], label %[[ATOMIC_OP14]]
// NATIVE:       [[ATOMIC_CONT18]]:
// NATIVE-NEXT:    ret void
//
// LIBCALL-LABEL: define dso_local void @foo(
// LIBCALL-SAME: i32 noundef [[X:%.*]]) #[[ATTR0:[0-9]+]] {
// LIBCALL-NEXT:  [[ENTRY:.*]]:
// LIBCALL-NEXT:    [[X_ADDR:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[I:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[J:%.*]] = alloca i16, align 2
// LIBCALL-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP5:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP7:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP8:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP9:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i16, align 2
// LIBCALL-NEXT:    [[ATOMIC_TEMP18:%.*]] = alloca i16, align 2
// LIBCALL-NEXT:    [[ATOMIC_TEMP19:%.*]] = alloca i16, align 2
// LIBCALL-NEXT:    [[ATOMIC_TEMP20:%.*]] = alloca i16, align 2
// LIBCALL-NEXT:    store i32 [[X]], ptr [[X_ADDR]], align 4
// LIBCALL-NEXT:    store i32 0, ptr [[I]], align 4
// LIBCALL-NEXT:    store i16 0, ptr [[J]], align 2
// LIBCALL-NEXT:    call void @__atomic_load(i32 noundef 4, ptr noundef [[I]], ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// LIBCALL-NEXT:    [[TMP0:%.*]] = load i32, ptr [[ATOMIC_TEMP]], align 4
// LIBCALL-NEXT:    br label %[[ATOMIC_OP:.*]]
// LIBCALL:       [[ATOMIC_OP]]:
// LIBCALL-NEXT:    [[TMP1:%.*]] = phi i32 [ [[TMP0]], %[[ENTRY]] ], [ [[TMP2:%.*]], %[[ATOMIC_OP]] ]
// LIBCALL-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP1]], 2
// LIBCALL-NEXT:    store i32 [[TMP1]], ptr [[ATOMIC_TEMP1]], align 4
// LIBCALL-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP2]], align 4
// LIBCALL-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i32, ptr [[ATOMIC_TEMP2]], align 4
// LIBCALL-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_4:%.*]] = call i8 @__atomic_compare_exchange_4(ptr [[I]], ptr [[ATOMIC_TEMP1]], i32 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// LIBCALL-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_4]], 0
// LIBCALL-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP3]], ptr [[ATOMIC_TEMP1]], i64 4, i1 false)
// LIBCALL-NEXT:    [[TMP2]] = load i32, ptr [[ATOMIC_TEMP3]], align 4
// LIBCALL-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// LIBCALL:       [[ATOMIC_CONT]]:
// LIBCALL-NEXT:    call void @__atomic_load(i32 noundef 4, ptr noundef [[I]], ptr noundef [[ATOMIC_TEMP5]], i32 noundef 5)
// LIBCALL-NEXT:    [[TMP3:%.*]] = load i32, ptr [[ATOMIC_TEMP5]], align 4
// LIBCALL-NEXT:    br label %[[ATOMIC_OP4:.*]]
// LIBCALL:       [[ATOMIC_OP4]]:
// LIBCALL-NEXT:    [[TMP4:%.*]] = phi i32 [ [[TMP3]], %[[ATOMIC_CONT]] ], [ [[TMP5:%.*]], %[[ATOMIC_OP4]] ]
// LIBCALL-NEXT:    [[DIV:%.*]] = sdiv i32 [[TMP4]], 2
// LIBCALL-NEXT:    store i32 [[TMP4]], ptr [[ATOMIC_TEMP7]], align 4
// LIBCALL-NEXT:    store i32 [[DIV]], ptr [[ATOMIC_TEMP8]], align 4
// LIBCALL-NEXT:    [[CMPXCHG_DESIRED10:%.*]] = load i32, ptr [[ATOMIC_TEMP8]], align 4
// LIBCALL-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_411:%.*]] = call i8 @__atomic_compare_exchange_4(ptr [[I]], ptr [[ATOMIC_TEMP7]], i32 [[CMPXCHG_DESIRED10]], i32 5, i32 5)
// LIBCALL-NEXT:    [[CMPXCHG_SUCCESS12:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_411]], 0
// LIBCALL-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP9]], ptr [[ATOMIC_TEMP7]], i64 4, i1 false)
// LIBCALL-NEXT:    [[TMP5]] = load i32, ptr [[ATOMIC_TEMP9]], align 4
// LIBCALL-NEXT:    br i1 [[CMPXCHG_SUCCESS12]], label %[[ATOMIC_CONT6:.*]], label %[[ATOMIC_OP4]]
// LIBCALL:       [[ATOMIC_CONT6]]:
// LIBCALL-NEXT:    [[TMP6:%.*]] = load i32, ptr [[X_ADDR]], align 4
// LIBCALL-NEXT:    call void @__atomic_load(i32 noundef 2, ptr noundef [[J]], ptr noundef [[ATOMIC_TEMP14]], i32 noundef 5)
// LIBCALL-NEXT:    [[TMP7:%.*]] = load i16, ptr [[ATOMIC_TEMP14]], align 2
// LIBCALL-NEXT:    br label %[[ATOMIC_OP13:.*]]
// LIBCALL:       [[ATOMIC_OP13]]:
// LIBCALL-NEXT:    [[TMP8:%.*]] = phi i16 [ [[TMP7]], %[[ATOMIC_CONT6]] ], [ [[TMP9:%.*]], %[[ATOMIC_OP13]] ]
// LIBCALL-NEXT:    [[CONV:%.*]] = zext i16 [[TMP8]] to i32
// LIBCALL-NEXT:    [[DIV15:%.*]] = sdiv i32 [[CONV]], [[TMP6]]
// LIBCALL-NEXT:    [[CONV16:%.*]] = trunc i32 [[DIV15]] to i16
// LIBCALL-NEXT:    store i16 [[TMP8]], ptr [[ATOMIC_TEMP18]], align 2
// LIBCALL-NEXT:    store i16 [[CONV16]], ptr [[ATOMIC_TEMP19]], align 2
// LIBCALL-NEXT:    [[CMPXCHG_DESIRED21:%.*]] = load i16, ptr [[ATOMIC_TEMP19]], align 2
// LIBCALL-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_2:%.*]] = call i8 @__atomic_compare_exchange_2(ptr [[J]], ptr [[ATOMIC_TEMP18]], i16 [[CMPXCHG_DESIRED21]], i32 5, i32 5)
// LIBCALL-NEXT:    [[CMPXCHG_SUCCESS22:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_2]], 0
// LIBCALL-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP20]], ptr [[ATOMIC_TEMP18]], i64 2, i1 false)
// LIBCALL-NEXT:    [[TMP9]] = load i16, ptr [[ATOMIC_TEMP20]], align 2
// LIBCALL-NEXT:    br i1 [[CMPXCHG_SUCCESS22]], label %[[ATOMIC_CONT17:.*]], label %[[ATOMIC_OP13]]
// LIBCALL:       [[ATOMIC_CONT17]]:
// LIBCALL-NEXT:    ret void
//
void foo(int x)
{
  _Atomic(int) i = 0;
  _Atomic(short) j = 0;
  // Check that multiply / divides on atomics produce a cmpxchg loop
  i *= 2;
  i /= 2;
  j /= x;

}


extern _Atomic _Bool b;

// NATIVE-LABEL: define dso_local zeroext i1 @bar(
// NATIVE-SAME: ) #[[ATTR0]] {
// NATIVE-NEXT:  [[ENTRY:.*:]]
// NATIVE-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i8, ptr @b seq_cst, align 1
// NATIVE-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[ATOMIC_LOAD]] to i1
// NATIVE-NEXT:    ret i1 [[LOADEDV]]
//
// LIBCALL-LABEL: define dso_local zeroext i1 @bar(
// LIBCALL-SAME: ) #[[ATTR0]] {
// LIBCALL-NEXT:  [[ENTRY:.*:]]
// LIBCALL-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i8, align 1
// LIBCALL-NEXT:    call void @__atomic_load(i32 noundef 1, ptr noundef @b, ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// LIBCALL-NEXT:    [[TMP0:%.*]] = load i8, ptr [[ATOMIC_TEMP]], align 1
// LIBCALL-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// LIBCALL-NEXT:    ret i1 [[LOADEDV]]
//
_Bool bar(void) {

  return b;
}

extern _Atomic(_Complex int) x;

// NATIVE-LABEL: define dso_local void @baz(
// NATIVE-SAME: i32 noundef [[Y:%.*]]) #[[ATTR0]] {
// NATIVE-NEXT:  [[ENTRY:.*:]]
// NATIVE-NEXT:    [[Y_ADDR:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { i32, i32 }, align 8
// NATIVE-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { i32, i32 }, align 8
// NATIVE-NEXT:    store i32 [[Y]], ptr [[Y_ADDR]], align 4
// NATIVE-NEXT:    [[TMP0:%.*]] = load i32, ptr [[Y_ADDR]], align 4
// NATIVE-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i64, ptr @x seq_cst, align 8
// NATIVE-NEXT:    store i64 [[ATOMIC_LOAD]], ptr [[ATOMIC_TEMP]], align 8
// NATIVE-NEXT:    [[ATOMIC_TEMP_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP]], i32 0, i32 0
// NATIVE-NEXT:    [[ATOMIC_TEMP_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP_REALP]], align 8
// NATIVE-NEXT:    [[ATOMIC_TEMP_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP]], i32 0, i32 1
// NATIVE-NEXT:    [[ATOMIC_TEMP_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP_IMAGP]], align 4
// NATIVE-NEXT:    [[ADD_R:%.*]] = add i32 [[ATOMIC_TEMP_REAL]], [[TMP0]]
// NATIVE-NEXT:    [[ADD_I:%.*]] = add i32 [[ATOMIC_TEMP_IMAG]], 0
// NATIVE-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 0
// NATIVE-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 1
// NATIVE-NEXT:    store i32 [[ADD_R]], ptr [[ATOMIC_TEMP1_REALP]], align 8
// NATIVE-NEXT:    store i32 [[ADD_I]], ptr [[ATOMIC_TEMP1_IMAGP]], align 4
// NATIVE-NEXT:    [[TMP1:%.*]] = load i64, ptr [[ATOMIC_TEMP1]], align 8
// NATIVE-NEXT:    store atomic i64 [[TMP1]], ptr @x seq_cst, align 8
// NATIVE-NEXT:    ret void
//
// LIBCALL-LABEL: define dso_local void @baz(
// LIBCALL-SAME: i32 noundef [[Y:%.*]]) #[[ATTR0]] {
// LIBCALL-NEXT:  [[ENTRY:.*:]]
// LIBCALL-NEXT:    [[Y_ADDR:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { i32, i32 }, align 8
// LIBCALL-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { i32, i32 }, align 8
// LIBCALL-NEXT:    store i32 [[Y]], ptr [[Y_ADDR]], align 4
// LIBCALL-NEXT:    [[TMP0:%.*]] = load i32, ptr [[Y_ADDR]], align 4
// LIBCALL-NEXT:    call void @__atomic_load(i32 noundef 8, ptr noundef @x, ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// LIBCALL-NEXT:    [[ATOMIC_TEMP_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP]], i32 0, i32 0
// LIBCALL-NEXT:    [[ATOMIC_TEMP_REAL:%.*]] = load i32, ptr [[ATOMIC_TEMP_REALP]], align 8
// LIBCALL-NEXT:    [[ATOMIC_TEMP_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP]], i32 0, i32 1
// LIBCALL-NEXT:    [[ATOMIC_TEMP_IMAG:%.*]] = load i32, ptr [[ATOMIC_TEMP_IMAGP]], align 4
// LIBCALL-NEXT:    [[ADD_R:%.*]] = add i32 [[ATOMIC_TEMP_REAL]], [[TMP0]]
// LIBCALL-NEXT:    [[ADD_I:%.*]] = add i32 [[ATOMIC_TEMP_IMAG]], 0
// LIBCALL-NEXT:    [[ATOMIC_TEMP1_REALP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 0
// LIBCALL-NEXT:    [[ATOMIC_TEMP1_IMAGP:%.*]] = getelementptr inbounds { i32, i32 }, ptr [[ATOMIC_TEMP1]], i32 0, i32 1
// LIBCALL-NEXT:    store i32 [[ADD_R]], ptr [[ATOMIC_TEMP1_REALP]], align 8
// LIBCALL-NEXT:    store i32 [[ADD_I]], ptr [[ATOMIC_TEMP1_IMAGP]], align 4
// LIBCALL-NEXT:    call void @__atomic_store(i32 noundef 8, ptr noundef @x, ptr noundef [[ATOMIC_TEMP1]], i32 noundef 5)
// LIBCALL-NEXT:    ret void
//
void baz(int y) {

  x += y;
}


// CHECK-LABEL: define dso_local i32 @compound_add(
// CHECK-SAME: i32 [[IN:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[IN_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[IN]], ptr [[IN_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = atomicrmw add ptr [[IN_ADDR]], i32 5 seq_cst, align 4
// CHECK-NEXT:    [[TMP1:%.*]] = add i32 [[TMP0]], 5
// CHECK-NEXT:    ret i32 [[TMP1]]
//
_Atomic(int) compound_add(_Atomic(int) in) {

  return (in += 5);
}

// CHECK-LABEL: define dso_local i32 @compound_sub(
// CHECK-SAME: i32 [[IN:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[IN_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[IN]], ptr [[IN_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = atomicrmw sub ptr [[IN_ADDR]], i32 5 seq_cst, align 4
// CHECK-NEXT:    [[TMP1:%.*]] = sub i32 [[TMP0]], 5
// CHECK-NEXT:    ret i32 [[TMP1]]
//
_Atomic(int) compound_sub(_Atomic(int) in) {

  return (in -= 5);
}

// CHECK-LABEL: define dso_local i32 @compound_xor(
// CHECK-SAME: i32 [[IN:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[IN_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[IN]], ptr [[IN_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = atomicrmw xor ptr [[IN_ADDR]], i32 5 seq_cst, align 4
// CHECK-NEXT:    [[TMP1:%.*]] = xor i32 [[TMP0]], 5
// CHECK-NEXT:    ret i32 [[TMP1]]
//
_Atomic(int) compound_xor(_Atomic(int) in) {

  return (in ^= 5);
}

// CHECK-LABEL: define dso_local i32 @compound_or(
// CHECK-SAME: i32 [[IN:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[IN_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[IN]], ptr [[IN_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = atomicrmw or ptr [[IN_ADDR]], i32 5 seq_cst, align 4
// CHECK-NEXT:    [[TMP1:%.*]] = or i32 [[TMP0]], 5
// CHECK-NEXT:    ret i32 [[TMP1]]
//
_Atomic(int) compound_or(_Atomic(int) in) {

  return (in |= 5);
}

// CHECK-LABEL: define dso_local i32 @compound_and(
// CHECK-SAME: i32 [[IN:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[IN_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[IN]], ptr [[IN_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = atomicrmw and ptr [[IN_ADDR]], i32 5 seq_cst, align 4
// CHECK-NEXT:    [[TMP1:%.*]] = and i32 [[TMP0]], 5
// CHECK-NEXT:    ret i32 [[TMP1]]
//
_Atomic(int) compound_and(_Atomic(int) in) {

  return (in &= 5);
}

// NATIVE-LABEL: define dso_local i32 @compound_mul(
// NATIVE-SAME: i32 [[IN:%.*]]) #[[ATTR0]] {
// NATIVE-NEXT:  [[ENTRY:.*]]:
// NATIVE-NEXT:    [[IN_ADDR:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i32, align 4
// NATIVE-NEXT:    store i32 [[IN]], ptr [[IN_ADDR]], align 4
// NATIVE-NEXT:    [[ATOMIC_LOAD:%.*]] = load atomic i32, ptr [[IN_ADDR]] seq_cst, align 4
// NATIVE-NEXT:    br label %[[ATOMIC_OP:.*]]
// NATIVE:       [[ATOMIC_OP]]:
// NATIVE-NEXT:    [[TMP0:%.*]] = phi i32 [ [[ATOMIC_LOAD]], %[[ENTRY]] ], [ [[TMP1:%.*]], %[[ATOMIC_OP]] ]
// NATIVE-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP0]], 5
// NATIVE-NEXT:    store i32 [[TMP0]], ptr [[ATOMIC_TEMP]], align 4
// NATIVE-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP1]], align 4
// NATIVE-NEXT:    [[CMPXCHG_EXPECTED:%.*]] = load i32, ptr [[ATOMIC_TEMP]], align 4
// NATIVE-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i32, ptr [[ATOMIC_TEMP1]], align 4
// NATIVE-NEXT:    [[CMPXCHG_PAIR:%.*]] = cmpxchg ptr [[IN_ADDR]], i32 [[CMPXCHG_EXPECTED]], i32 [[CMPXCHG_DESIRED]] seq_cst seq_cst, align 4
// NATIVE-NEXT:    [[CMPXCHG_PREV:%.*]] = extractvalue { i32, i1 } [[CMPXCHG_PAIR]], 0
// NATIVE-NEXT:    store i32 [[CMPXCHG_PREV]], ptr [[ATOMIC_TEMP2]], align 4
// NATIVE-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = extractvalue { i32, i1 } [[CMPXCHG_PAIR]], 1
// NATIVE-NEXT:    [[TMP1]] = load i32, ptr [[ATOMIC_TEMP2]], align 4
// NATIVE-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// NATIVE:       [[ATOMIC_CONT]]:
// NATIVE-NEXT:    ret i32 [[MUL]]
//
// LIBCALL-LABEL: define dso_local i32 @compound_mul(
// LIBCALL-SAME: i32 [[IN:%.*]]) #[[ATTR0]] {
// LIBCALL-NEXT:  [[ENTRY:.*]]:
// LIBCALL-NEXT:    [[IN_ADDR:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i32, align 4
// LIBCALL-NEXT:    store i32 [[IN]], ptr [[IN_ADDR]], align 4
// LIBCALL-NEXT:    call void @__atomic_load(i32 noundef 4, ptr noundef [[IN_ADDR]], ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// LIBCALL-NEXT:    [[TMP0:%.*]] = load i32, ptr [[ATOMIC_TEMP]], align 4
// LIBCALL-NEXT:    br label %[[ATOMIC_OP:.*]]
// LIBCALL:       [[ATOMIC_OP]]:
// LIBCALL-NEXT:    [[TMP1:%.*]] = phi i32 [ [[TMP0]], %[[ENTRY]] ], [ [[TMP2:%.*]], %[[ATOMIC_OP]] ]
// LIBCALL-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP1]], 5
// LIBCALL-NEXT:    store i32 [[TMP1]], ptr [[ATOMIC_TEMP1]], align 4
// LIBCALL-NEXT:    store i32 [[MUL]], ptr [[ATOMIC_TEMP2]], align 4
// LIBCALL-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i32, ptr [[ATOMIC_TEMP2]], align 4
// LIBCALL-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_4:%.*]] = call i8 @__atomic_compare_exchange_4(ptr [[IN_ADDR]], ptr [[ATOMIC_TEMP1]], i32 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// LIBCALL-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_4]], 0
// LIBCALL-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP3]], ptr [[ATOMIC_TEMP1]], i64 4, i1 false)
// LIBCALL-NEXT:    [[TMP2]] = load i32, ptr [[ATOMIC_TEMP3]], align 4
// LIBCALL-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// LIBCALL:       [[ATOMIC_CONT]]:
// LIBCALL-NEXT:    ret i32 [[MUL]]
//
_Atomic(int) compound_mul(_Atomic(int) in) {

  return (in *= 5);
}

