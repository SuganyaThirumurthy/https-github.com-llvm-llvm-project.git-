// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// RUN: %clang_cc1 %s -emit-llvm -o - -triple=armv5-unknown-freebsd -std=c11 | FileCheck %s

// Test that we are generating atomicrmw instructions, rather than
// compare-exchange loops for common atomic ops.  This makes a big difference
// on RISC platforms, where the compare-exchange loop becomes a ll/sc pair for
// the load and then another ll/sc in the loop, expanding to about 30
// instructions when it should be only 4.  It has a smaller, but still
// noticeable, impact on platforms like x86 and RISC-V, where there are atomic
// RMW instructions.
//
// We currently emit cmpxchg loops for most operations on _Bools, because
// they're sufficiently rare that it's not worth making sure that the semantics
// are correct.

struct elem;

struct ptr {
    struct elem *ptr;
};

struct elem {
    _Atomic(struct ptr) link;
};

struct ptr object;



typedef int __attribute__((vector_size(16))) vector;

_Atomic(_Bool) b;
_Atomic(int) i;
_Atomic(long long) l;
_Atomic(short) s;
_Atomic(char*) p;
_Atomic(float) f;
_Atomic(vector) v;

// CHECK-LABEL: define dso_local arm_aapcscc void @testinc(
// CHECK-SAME: ) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[TMP0:%.*]] = atomicrmw xchg ptr @b, i8 1 seq_cst, align 1
// CHECK-NEXT:    [[TMP1:%.*]] = atomicrmw add ptr @i, i32 1 seq_cst, align 4
// CHECK-NEXT:    [[TMP2:%.*]] = atomicrmw add ptr @l, i64 1 seq_cst, align 8
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw add ptr @s, i16 1 seq_cst, align 2
// CHECK-NEXT:    store atomic i8 1, ptr @b seq_cst, align 1
// CHECK-NEXT:    [[TMP4:%.*]] = atomicrmw add ptr @i, i32 1 seq_cst, align 4
// CHECK-NEXT:    [[TMP5:%.*]] = add i32 [[TMP4]], 1
// CHECK-NEXT:    [[TMP6:%.*]] = atomicrmw add ptr @l, i64 1 seq_cst, align 8
// CHECK-NEXT:    [[TMP7:%.*]] = add i64 [[TMP6]], 1
// CHECK-NEXT:    [[TMP8:%.*]] = atomicrmw add ptr @s, i16 1 seq_cst, align 2
// CHECK-NEXT:    [[TMP9:%.*]] = add i16 [[TMP8]], 1
// CHECK-NEXT:    ret void
//
void testinc(void)
{
  // Special case for suffix bool++, sets to true and returns the old value.
  b++;
  i++;
  l++;
  s++;
  // Prefix increment
  // Special case for bool: set to true and return true
  ++b;
  // Currently, we have no variant of atomicrmw that returns the new value, so
  // we have to generate an atomic add, which returns the old value, and then a
  // non-atomic add.
  ++i;
  ++l;
  ++s;
}
// CHECK-LABEL: define dso_local arm_aapcscc void @testdec(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*]]:
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP6:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP12:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP13:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP14:%.*]] = alloca i8, align 1
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 1, ptr noundef @b, ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[ATOMIC_TEMP]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8
// CHECK-NEXT:    br label %[[ATOMIC_OP:.*]]
// CHECK:       [[ATOMIC_OP]]:
// CHECK-NEXT:    [[TMP1:%.*]] = phi i8 [ [[STOREDV]], %[[ENTRY]] ], [ [[STOREDV5:%.*]], %[[ATOMIC_OP]] ]
// CHECK-NEXT:    [[DEC:%.*]] = add i8 [[TMP1]], -1
// CHECK-NEXT:    store i8 [[TMP1]], ptr [[ATOMIC_TEMP1]], align 1
// CHECK-NEXT:    store i8 [[DEC]], ptr [[ATOMIC_TEMP2]], align 1
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i8, ptr [[ATOMIC_TEMP2]], align 1
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_1:%.*]] = call i8 @__atomic_compare_exchange_1(ptr @b, ptr [[ATOMIC_TEMP1]], i8 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_1]], 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP3]], ptr [[ATOMIC_TEMP1]], i64 1, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[LOADEDV4:%.*]] = trunc i8 [[TMP2]] to i1
// CHECK-NEXT:    [[STOREDV5]] = zext i1 [[LOADEDV4]] to i8
// CHECK-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// CHECK:       [[ATOMIC_CONT]]:
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @i, i32 1 seq_cst, align 4
// CHECK-NEXT:    [[TMP4:%.*]] = atomicrmw sub ptr @l, i64 1 seq_cst, align 8
// CHECK-NEXT:    [[TMP5:%.*]] = atomicrmw sub ptr @s, i16 1 seq_cst, align 2
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 1, ptr noundef @b, ptr noundef [[ATOMIC_TEMP6]], i32 noundef 5)
// CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[ATOMIC_TEMP6]], align 1
// CHECK-NEXT:    [[LOADEDV7:%.*]] = trunc i8 [[TMP6]] to i1
// CHECK-NEXT:    [[STOREDV9:%.*]] = zext i1 [[LOADEDV7]] to i8
// CHECK-NEXT:    br label %[[ATOMIC_OP8:.*]]
// CHECK:       [[ATOMIC_OP8]]:
// CHECK-NEXT:    [[TMP7:%.*]] = phi i8 [ [[STOREDV9]], %[[ATOMIC_CONT]] ], [ [[STOREDV19:%.*]], %[[ATOMIC_OP8]] ]
// CHECK-NEXT:    [[DEC10:%.*]] = add i8 [[TMP7]], -1
// CHECK-NEXT:    store i8 [[TMP7]], ptr [[ATOMIC_TEMP12]], align 1
// CHECK-NEXT:    store i8 [[DEC10]], ptr [[ATOMIC_TEMP13]], align 1
// CHECK-NEXT:    [[CMPXCHG_DESIRED15:%.*]] = load i8, ptr [[ATOMIC_TEMP13]], align 1
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_116:%.*]] = call i8 @__atomic_compare_exchange_1(ptr @b, ptr [[ATOMIC_TEMP12]], i8 [[CMPXCHG_DESIRED15]], i32 5, i32 5)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS17:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_116]], 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP14]], ptr [[ATOMIC_TEMP12]], i64 1, i1 false)
// CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[ATOMIC_TEMP14]], align 1
// CHECK-NEXT:    [[LOADEDV18:%.*]] = trunc i8 [[TMP8]] to i1
// CHECK-NEXT:    [[STOREDV19]] = zext i1 [[LOADEDV18]] to i8
// CHECK-NEXT:    br i1 [[CMPXCHG_SUCCESS17]], label %[[ATOMIC_CONT11:.*]], label %[[ATOMIC_OP8]]
// CHECK:       [[ATOMIC_CONT11]]:
// CHECK-NEXT:    [[TMP9:%.*]] = atomicrmw sub ptr @i, i32 1 seq_cst, align 4
// CHECK-NEXT:    [[TMP10:%.*]] = sub i32 [[TMP9]], 1
// CHECK-NEXT:    [[TMP11:%.*]] = atomicrmw sub ptr @l, i64 1 seq_cst, align 8
// CHECK-NEXT:    [[TMP12:%.*]] = sub i64 [[TMP11]], 1
// CHECK-NEXT:    [[TMP13:%.*]] = atomicrmw sub ptr @s, i16 1 seq_cst, align 2
// CHECK-NEXT:    [[TMP14:%.*]] = sub i16 [[TMP13]], 1
// CHECK-NEXT:    ret void
//
void testdec(void)
{
  b--;
  i--;
  l--;
  s--;
  --b;
  --i;
  --l;
  --s;
}
// CHECK-LABEL: define dso_local arm_aapcscc void @testaddeq(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*]]:
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP4:%.*]] = alloca i8, align 1
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 1, ptr noundef @b, ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[ATOMIC_TEMP]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8
// CHECK-NEXT:    br label %[[ATOMIC_OP:.*]]
// CHECK:       [[ATOMIC_OP]]:
// CHECK-NEXT:    [[TMP1:%.*]] = phi i8 [ [[STOREDV]], %[[ENTRY]] ], [ [[STOREDV6:%.*]], %[[ATOMIC_OP]] ]
// CHECK-NEXT:    [[CONV:%.*]] = zext i8 [[TMP1]] to i32
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV]], 42
// CHECK-NEXT:    [[CONV1:%.*]] = trunc i32 [[ADD]] to i8
// CHECK-NEXT:    store i8 [[TMP1]], ptr [[ATOMIC_TEMP2]], align 1
// CHECK-NEXT:    store i8 [[CONV1]], ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i8, ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_1:%.*]] = call i8 @__atomic_compare_exchange_1(ptr @b, ptr [[ATOMIC_TEMP2]], i8 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_1]], 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP4]], ptr [[ATOMIC_TEMP2]], i64 1, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[ATOMIC_TEMP4]], align 1
// CHECK-NEXT:    [[LOADEDV5:%.*]] = trunc i8 [[TMP2]] to i1
// CHECK-NEXT:    [[STOREDV6]] = zext i1 [[LOADEDV5]] to i8
// CHECK-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// CHECK:       [[ATOMIC_CONT]]:
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw add ptr @i, i32 42 seq_cst, align 4
// CHECK-NEXT:    [[TMP4:%.*]] = add i32 [[TMP3]], 42
// CHECK-NEXT:    [[TMP5:%.*]] = atomicrmw add ptr @l, i64 42 seq_cst, align 8
// CHECK-NEXT:    [[TMP6:%.*]] = add i64 [[TMP5]], 42
// CHECK-NEXT:    [[TMP7:%.*]] = atomicrmw add ptr @s, i16 42 seq_cst, align 2
// CHECK-NEXT:    [[TMP8:%.*]] = add i16 [[TMP7]], 42
// CHECK-NEXT:    ret void
//
void testaddeq(void)
{
  b += 42;
  i += 42;
  l += 42;
  s += 42;
}
// CHECK-LABEL: define dso_local arm_aapcscc void @testsubeq(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*]]:
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP4:%.*]] = alloca i8, align 1
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 1, ptr noundef @b, ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[ATOMIC_TEMP]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8
// CHECK-NEXT:    br label %[[ATOMIC_OP:.*]]
// CHECK:       [[ATOMIC_OP]]:
// CHECK-NEXT:    [[TMP1:%.*]] = phi i8 [ [[STOREDV]], %[[ENTRY]] ], [ [[STOREDV6:%.*]], %[[ATOMIC_OP]] ]
// CHECK-NEXT:    [[CONV:%.*]] = zext i8 [[TMP1]] to i32
// CHECK-NEXT:    [[SUB:%.*]] = sub nsw i32 [[CONV]], 42
// CHECK-NEXT:    [[CONV1:%.*]] = trunc i32 [[SUB]] to i8
// CHECK-NEXT:    store i8 [[TMP1]], ptr [[ATOMIC_TEMP2]], align 1
// CHECK-NEXT:    store i8 [[CONV1]], ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i8, ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_1:%.*]] = call i8 @__atomic_compare_exchange_1(ptr @b, ptr [[ATOMIC_TEMP2]], i8 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_1]], 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP4]], ptr [[ATOMIC_TEMP2]], i64 1, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[ATOMIC_TEMP4]], align 1
// CHECK-NEXT:    [[LOADEDV5:%.*]] = trunc i8 [[TMP2]] to i1
// CHECK-NEXT:    [[STOREDV6]] = zext i1 [[LOADEDV5]] to i8
// CHECK-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// CHECK:       [[ATOMIC_CONT]]:
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw sub ptr @i, i32 42 seq_cst, align 4
// CHECK-NEXT:    [[TMP4:%.*]] = sub i32 [[TMP3]], 42
// CHECK-NEXT:    [[TMP5:%.*]] = atomicrmw sub ptr @l, i64 42 seq_cst, align 8
// CHECK-NEXT:    [[TMP6:%.*]] = sub i64 [[TMP5]], 42
// CHECK-NEXT:    [[TMP7:%.*]] = atomicrmw sub ptr @s, i16 42 seq_cst, align 2
// CHECK-NEXT:    [[TMP8:%.*]] = sub i16 [[TMP7]], 42
// CHECK-NEXT:    ret void
//
void testsubeq(void)
{
  b -= 42;
  i -= 42;
  l -= 42;
  s -= 42;
}
// CHECK-LABEL: define dso_local arm_aapcscc void @testxoreq(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*]]:
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP4:%.*]] = alloca i8, align 1
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 1, ptr noundef @b, ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[ATOMIC_TEMP]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8
// CHECK-NEXT:    br label %[[ATOMIC_OP:.*]]
// CHECK:       [[ATOMIC_OP]]:
// CHECK-NEXT:    [[TMP1:%.*]] = phi i8 [ [[STOREDV]], %[[ENTRY]] ], [ [[STOREDV6:%.*]], %[[ATOMIC_OP]] ]
// CHECK-NEXT:    [[CONV:%.*]] = zext i8 [[TMP1]] to i32
// CHECK-NEXT:    [[XOR:%.*]] = xor i32 [[CONV]], 42
// CHECK-NEXT:    [[CONV1:%.*]] = trunc i32 [[XOR]] to i8
// CHECK-NEXT:    store i8 [[TMP1]], ptr [[ATOMIC_TEMP2]], align 1
// CHECK-NEXT:    store i8 [[CONV1]], ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i8, ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_1:%.*]] = call i8 @__atomic_compare_exchange_1(ptr @b, ptr [[ATOMIC_TEMP2]], i8 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_1]], 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP4]], ptr [[ATOMIC_TEMP2]], i64 1, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[ATOMIC_TEMP4]], align 1
// CHECK-NEXT:    [[LOADEDV5:%.*]] = trunc i8 [[TMP2]] to i1
// CHECK-NEXT:    [[STOREDV6]] = zext i1 [[LOADEDV5]] to i8
// CHECK-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// CHECK:       [[ATOMIC_CONT]]:
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw xor ptr @i, i32 42 seq_cst, align 4
// CHECK-NEXT:    [[TMP4:%.*]] = xor i32 [[TMP3]], 42
// CHECK-NEXT:    [[TMP5:%.*]] = atomicrmw xor ptr @l, i64 42 seq_cst, align 8
// CHECK-NEXT:    [[TMP6:%.*]] = xor i64 [[TMP5]], 42
// CHECK-NEXT:    [[TMP7:%.*]] = atomicrmw xor ptr @s, i16 42 seq_cst, align 2
// CHECK-NEXT:    [[TMP8:%.*]] = xor i16 [[TMP7]], 42
// CHECK-NEXT:    ret void
//
void testxoreq(void)
{
  b ^= 42;
  i ^= 42;
  l ^= 42;
  s ^= 42;
}
// CHECK-LABEL: define dso_local arm_aapcscc void @testoreq(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*]]:
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP4:%.*]] = alloca i8, align 1
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 1, ptr noundef @b, ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[ATOMIC_TEMP]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8
// CHECK-NEXT:    br label %[[ATOMIC_OP:.*]]
// CHECK:       [[ATOMIC_OP]]:
// CHECK-NEXT:    [[TMP1:%.*]] = phi i8 [ [[STOREDV]], %[[ENTRY]] ], [ [[STOREDV6:%.*]], %[[ATOMIC_OP]] ]
// CHECK-NEXT:    [[CONV:%.*]] = zext i8 [[TMP1]] to i32
// CHECK-NEXT:    [[OR:%.*]] = or i32 [[CONV]], 42
// CHECK-NEXT:    [[CONV1:%.*]] = trunc i32 [[OR]] to i8
// CHECK-NEXT:    store i8 [[TMP1]], ptr [[ATOMIC_TEMP2]], align 1
// CHECK-NEXT:    store i8 [[CONV1]], ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i8, ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_1:%.*]] = call i8 @__atomic_compare_exchange_1(ptr @b, ptr [[ATOMIC_TEMP2]], i8 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_1]], 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP4]], ptr [[ATOMIC_TEMP2]], i64 1, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[ATOMIC_TEMP4]], align 1
// CHECK-NEXT:    [[LOADEDV5:%.*]] = trunc i8 [[TMP2]] to i1
// CHECK-NEXT:    [[STOREDV6]] = zext i1 [[LOADEDV5]] to i8
// CHECK-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// CHECK:       [[ATOMIC_CONT]]:
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw or ptr @i, i32 42 seq_cst, align 4
// CHECK-NEXT:    [[TMP4:%.*]] = or i32 [[TMP3]], 42
// CHECK-NEXT:    [[TMP5:%.*]] = atomicrmw or ptr @l, i64 42 seq_cst, align 8
// CHECK-NEXT:    [[TMP6:%.*]] = or i64 [[TMP5]], 42
// CHECK-NEXT:    [[TMP7:%.*]] = atomicrmw or ptr @s, i16 42 seq_cst, align 2
// CHECK-NEXT:    [[TMP8:%.*]] = or i16 [[TMP7]], 42
// CHECK-NEXT:    ret void
//
void testoreq(void)
{
  b |= 42;
  i |= 42;
  l |= 42;
  s |= 42;
}
// CHECK-LABEL: define dso_local arm_aapcscc void @testandeq(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*]]:
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[ATOMIC_TEMP4:%.*]] = alloca i8, align 1
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 1, ptr noundef @b, ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[ATOMIC_TEMP]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[LOADEDV]] to i8
// CHECK-NEXT:    br label %[[ATOMIC_OP:.*]]
// CHECK:       [[ATOMIC_OP]]:
// CHECK-NEXT:    [[TMP1:%.*]] = phi i8 [ [[STOREDV]], %[[ENTRY]] ], [ [[STOREDV6:%.*]], %[[ATOMIC_OP]] ]
// CHECK-NEXT:    [[CONV:%.*]] = zext i8 [[TMP1]] to i32
// CHECK-NEXT:    [[AND:%.*]] = and i32 [[CONV]], 42
// CHECK-NEXT:    [[CONV1:%.*]] = trunc i32 [[AND]] to i8
// CHECK-NEXT:    store i8 [[TMP1]], ptr [[ATOMIC_TEMP2]], align 1
// CHECK-NEXT:    store i8 [[CONV1]], ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i8, ptr [[ATOMIC_TEMP3]], align 1
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_1:%.*]] = call i8 @__atomic_compare_exchange_1(ptr @b, ptr [[ATOMIC_TEMP2]], i8 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_1]], 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[ATOMIC_TEMP4]], ptr [[ATOMIC_TEMP2]], i64 1, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[ATOMIC_TEMP4]], align 1
// CHECK-NEXT:    [[LOADEDV5:%.*]] = trunc i8 [[TMP2]] to i1
// CHECK-NEXT:    [[STOREDV6]] = zext i1 [[LOADEDV5]] to i8
// CHECK-NEXT:    br i1 [[CMPXCHG_SUCCESS]], label %[[ATOMIC_CONT:.*]], label %[[ATOMIC_OP]]
// CHECK:       [[ATOMIC_CONT]]:
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw and ptr @i, i32 42 seq_cst, align 4
// CHECK-NEXT:    [[TMP4:%.*]] = and i32 [[TMP3]], 42
// CHECK-NEXT:    [[TMP5:%.*]] = atomicrmw and ptr @l, i64 42 seq_cst, align 8
// CHECK-NEXT:    [[TMP6:%.*]] = and i64 [[TMP5]], 42
// CHECK-NEXT:    [[TMP7:%.*]] = atomicrmw and ptr @s, i16 42 seq_cst, align 2
// CHECK-NEXT:    [[TMP8:%.*]] = and i16 [[TMP7]], 42
// CHECK-NEXT:    ret void
//
void testandeq(void)
{
  b &= 42;
  i &= 42;
  l &= 42;
  s &= 42;
}

// CHECK-LABEL: define dso_local arm_aapcscc void @testFloat(
// CHECK-SAME: ptr noundef [[FP:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[FP_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[X:%.*]] = alloca float, align 4
// CHECK-NEXT:    [[F:%.*]] = alloca float, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca float, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca float, align 4
// CHECK-NEXT:    store ptr [[FP]], ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    store float 1.000000e+00, ptr [[TMP0]], align 4
// CHECK-NEXT:    store float 2.000000e+00, ptr [[X]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 4, ptr noundef [[TMP1]], ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[TMP2:%.*]] = load float, ptr [[ATOMIC_TEMP]], align 4
// CHECK-NEXT:    store float [[TMP2]], ptr [[F]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load float, ptr [[F]], align 4
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    store float [[TMP3]], ptr [[ATOMIC_TEMP1]], align 4
// CHECK-NEXT:    call arm_aapcscc void @__atomic_store(i32 noundef 4, ptr noundef [[TMP4]], ptr noundef [[ATOMIC_TEMP1]], i32 noundef 5)
// CHECK-NEXT:    ret void
//
void testFloat(_Atomic(float) *fp) {

  __c11_atomic_init(fp, 1.0f);

  _Atomic(float) x = 2.0f;

  float f = *fp;

  *fp = f;

}

// CHECK-LABEL: define dso_local arm_aapcscc void @testComplexFloat(
// CHECK-SAME: ptr noundef [[FP:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[FP_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[X:%.*]] = alloca { float, float }, align 8
// CHECK-NEXT:    [[F:%.*]] = alloca { float, float }, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { float, float }, align 8
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca { float, float }, align 8
// CHECK-NEXT:    store ptr [[FP]], ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    [[DOTREALP:%.*]] = getelementptr inbounds { float, float }, ptr [[TMP0]], i32 0, i32 0
// CHECK-NEXT:    [[DOTIMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[TMP0]], i32 0, i32 1
// CHECK-NEXT:    store float 1.000000e+00, ptr [[DOTREALP]], align 8
// CHECK-NEXT:    store float 0.000000e+00, ptr [[DOTIMAGP]], align 4
// CHECK-NEXT:    [[X_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[X]], i32 0, i32 0
// CHECK-NEXT:    [[X_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[X]], i32 0, i32 1
// CHECK-NEXT:    store float 2.000000e+00, ptr [[X_REALP]], align 8
// CHECK-NEXT:    store float 0.000000e+00, ptr [[X_IMAGP]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 8, ptr noundef [[TMP1]], ptr noundef [[ATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[ATOMIC_TEMP_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[ATOMIC_TEMP_REAL:%.*]] = load float, ptr [[ATOMIC_TEMP_REALP]], align 8
// CHECK-NEXT:    [[ATOMIC_TEMP_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[ATOMIC_TEMP_IMAG:%.*]] = load float, ptr [[ATOMIC_TEMP_IMAGP]], align 4
// CHECK-NEXT:    [[F_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[F]], i32 0, i32 0
// CHECK-NEXT:    [[F_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[F]], i32 0, i32 1
// CHECK-NEXT:    store float [[ATOMIC_TEMP_REAL]], ptr [[F_REALP]], align 4
// CHECK-NEXT:    store float [[ATOMIC_TEMP_IMAG]], ptr [[F_IMAGP]], align 4
// CHECK-NEXT:    [[F_REALP1:%.*]] = getelementptr inbounds { float, float }, ptr [[F]], i32 0, i32 0
// CHECK-NEXT:    [[F_REAL:%.*]] = load float, ptr [[F_REALP1]], align 4
// CHECK-NEXT:    [[F_IMAGP2:%.*]] = getelementptr inbounds { float, float }, ptr [[F]], i32 0, i32 1
// CHECK-NEXT:    [[F_IMAG:%.*]] = load float, ptr [[F_IMAGP2]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    [[ATOMIC_TEMP3_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    [[ATOMIC_TEMP3_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ATOMIC_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    store float [[F_REAL]], ptr [[ATOMIC_TEMP3_REALP]], align 8
// CHECK-NEXT:    store float [[F_IMAG]], ptr [[ATOMIC_TEMP3_IMAGP]], align 4
// CHECK-NEXT:    call arm_aapcscc void @__atomic_store(i32 noundef 8, ptr noundef [[TMP2]], ptr noundef [[ATOMIC_TEMP3]], i32 noundef 5)
// CHECK-NEXT:    ret void
//
void testComplexFloat(_Atomic(_Complex float) *fp) {

  __c11_atomic_init(fp, 1.0f);

  _Atomic(_Complex float) x = 2.0f;

  _Complex float f = *fp;

  *fp = f;

}

typedef struct { short x, y, z, w; } S;
_Atomic S testStructGlobal = (S){1, 2, 3, 4};
// CHECK-LABEL: define dso_local arm_aapcscc void @testStruct(
// CHECK-SAME: ptr noundef [[FP:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[FP_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[X1:%.*]] = alloca [[STRUCT_S:%.*]], align 8
// CHECK-NEXT:    [[F:%.*]] = alloca [[STRUCT_S]], align 2
// CHECK-NEXT:    [[AGG_TMP_ENSURED:%.*]] = alloca [[STRUCT_S]], align 8
// CHECK-NEXT:    store ptr [[FP]], ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    [[X:%.*]] = getelementptr inbounds [[STRUCT_S]], ptr [[TMP0]], i32 0, i32 0
// CHECK-NEXT:    store i16 1, ptr [[X]], align 8
// CHECK-NEXT:    [[Y:%.*]] = getelementptr inbounds [[STRUCT_S]], ptr [[TMP0]], i32 0, i32 1
// CHECK-NEXT:    store i16 2, ptr [[Y]], align 2
// CHECK-NEXT:    [[Z:%.*]] = getelementptr inbounds [[STRUCT_S]], ptr [[TMP0]], i32 0, i32 2
// CHECK-NEXT:    store i16 3, ptr [[Z]], align 4
// CHECK-NEXT:    [[W:%.*]] = getelementptr inbounds [[STRUCT_S]], ptr [[TMP0]], i32 0, i32 3
// CHECK-NEXT:    store i16 4, ptr [[W]], align 2
// CHECK-NEXT:    [[X2:%.*]] = getelementptr inbounds [[STRUCT_S]], ptr [[X1]], i32 0, i32 0
// CHECK-NEXT:    store i16 1, ptr [[X2]], align 8
// CHECK-NEXT:    [[Y3:%.*]] = getelementptr inbounds [[STRUCT_S]], ptr [[X1]], i32 0, i32 1
// CHECK-NEXT:    store i16 2, ptr [[Y3]], align 2
// CHECK-NEXT:    [[Z4:%.*]] = getelementptr inbounds [[STRUCT_S]], ptr [[X1]], i32 0, i32 2
// CHECK-NEXT:    store i16 3, ptr [[Z4]], align 4
// CHECK-NEXT:    [[W5:%.*]] = getelementptr inbounds [[STRUCT_S]], ptr [[X1]], i32 0, i32 3
// CHECK-NEXT:    store i16 4, ptr [[W5]], align 2
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 8, ptr noundef [[TMP1]], ptr noundef [[F]], i32 noundef 5)
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 8 [[AGG_TMP_ENSURED]], ptr align 2 [[F]], i32 8, i1 false)
// CHECK-NEXT:    call arm_aapcscc void @__atomic_store(i32 noundef 8, ptr noundef [[TMP2]], ptr noundef [[AGG_TMP_ENSURED]], i32 noundef 5)
// CHECK-NEXT:    ret void
//
void testStruct(_Atomic(S) *fp) {

  __c11_atomic_init(fp, (S){1,2,3,4});

  _Atomic(S) x = (S){1,2,3,4};

  S f = *fp;

  *fp = f;

}

typedef struct { short x, y, z; } PS;
_Atomic PS testPromotedStructGlobal = (PS){1, 2, 3};
// CHECK-LABEL: define dso_local arm_aapcscc void @testPromotedStruct(
// CHECK-SAME: ptr noundef [[FP:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[FP_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[X1:%.*]] = alloca { [[STRUCT_PS:%.*]], [2 x i8] }, align 8
// CHECK-NEXT:    [[F:%.*]] = alloca [[STRUCT_PS]], align 2
// CHECK-NEXT:    [[ATOMIC_TO_NONATOMIC_TEMP:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    [[AGG_TMP_ENSURED:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    [[A:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[TMP:%.*]] = alloca [[STRUCT_PS]], align 2
// CHECK-NEXT:    [[ATOMIC_TO_NONATOMIC_TEMP5:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    store ptr [[FP]], ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[TMP0]], i8 0, i64 8, i1 false)
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds { [[STRUCT_PS]], [2 x i8] }, ptr [[TMP0]], i32 0, i32 0
// CHECK-NEXT:    [[X:%.*]] = getelementptr inbounds [[STRUCT_PS]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i16 1, ptr [[X]], align 8
// CHECK-NEXT:    [[Y:%.*]] = getelementptr inbounds [[STRUCT_PS]], ptr [[TMP1]], i32 0, i32 1
// CHECK-NEXT:    store i16 2, ptr [[Y]], align 2
// CHECK-NEXT:    [[Z:%.*]] = getelementptr inbounds [[STRUCT_PS]], ptr [[TMP1]], i32 0, i32 2
// CHECK-NEXT:    store i16 3, ptr [[Z]], align 4
// CHECK-NEXT:    call void @llvm.memset.p0.i32(ptr align 8 [[X1]], i8 0, i32 8, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds { [[STRUCT_PS]], [2 x i8] }, ptr [[X1]], i32 0, i32 0
// CHECK-NEXT:    [[X2:%.*]] = getelementptr inbounds [[STRUCT_PS]], ptr [[TMP2]], i32 0, i32 0
// CHECK-NEXT:    store i16 1, ptr [[X2]], align 8
// CHECK-NEXT:    [[Y3:%.*]] = getelementptr inbounds [[STRUCT_PS]], ptr [[TMP2]], i32 0, i32 1
// CHECK-NEXT:    store i16 2, ptr [[Y3]], align 2
// CHECK-NEXT:    [[Z4:%.*]] = getelementptr inbounds [[STRUCT_PS]], ptr [[TMP2]], i32 0, i32 2
// CHECK-NEXT:    store i16 3, ptr [[Z4]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 8, ptr noundef [[TMP3]], ptr noundef [[ATOMIC_TO_NONATOMIC_TEMP]], i32 noundef 5)
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds { [[STRUCT_PS]], [2 x i8] }, ptr [[ATOMIC_TO_NONATOMIC_TEMP]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 2 [[F]], ptr align 8 [[TMP4]], i32 6, i1 false)
// CHECK-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memset.p0.i32(ptr align 8 [[AGG_TMP_ENSURED]], i8 0, i32 8, i1 false)
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds { [[STRUCT_PS]], [2 x i8] }, ptr [[AGG_TMP_ENSURED]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 8 [[TMP6]], ptr align 2 [[F]], i32 6, i1 false)
// CHECK-NEXT:    call arm_aapcscc void @__atomic_store(i32 noundef 8, ptr noundef [[TMP5]], ptr noundef [[AGG_TMP_ENSURED]], i32 noundef 5)
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[FP_ADDR]], align 4
// CHECK-NEXT:    call arm_aapcscc void @__atomic_load(i32 noundef 8, ptr noundef [[TMP7]], ptr noundef [[ATOMIC_TO_NONATOMIC_TEMP5]], i32 noundef 5)
// CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds { [[STRUCT_PS]], [2 x i8] }, ptr [[ATOMIC_TO_NONATOMIC_TEMP5]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 2 [[TMP]], ptr align 8 [[TMP8]], i32 6, i1 false)
// CHECK-NEXT:    [[X6:%.*]] = getelementptr inbounds [[STRUCT_PS]], ptr [[TMP]], i32 0, i32 0
// CHECK-NEXT:    [[TMP9:%.*]] = load i16, ptr [[X6]], align 2
// CHECK-NEXT:    [[CONV:%.*]] = sext i16 [[TMP9]] to i32
// CHECK-NEXT:    store i32 [[CONV]], ptr [[A]], align 4
// CHECK-NEXT:    ret void
//
void testPromotedStruct(_Atomic(PS) *fp) {

  __c11_atomic_init(fp, (PS){1,2,3});

  _Atomic(PS) x = (PS){1,2,3};

  PS f = *fp;

  *fp = f;

  int a = ((PS)*fp).x;

}

// CHECK-LABEL: define dso_local arm_aapcscc void @test_promoted_load(
// CHECK-SAME: ptr dead_on_unwind noalias writable sret([[STRUCT_PS:%.*]]) align 2 [[AGG_RESULT:%.*]], ptr noundef [[ADDR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[ADDR_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    store ptr [[ADDR]], ptr [[ADDR_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[ADDR_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load atomic i64, ptr [[TMP0]] seq_cst, align 8
// CHECK-NEXT:    store i64 [[TMP1]], ptr [[ATOMIC_TEMP]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 2 [[AGG_RESULT]], ptr align 8 [[ATOMIC_TEMP]], i32 6, i1 false)
// CHECK-NEXT:    ret void
//
PS test_promoted_load(_Atomic(PS) *addr) {
  return __c11_atomic_load(addr, 5);
}

// CHECK-LABEL: define dso_local arm_aapcscc void @test_promoted_store(
// CHECK-SAME: ptr noundef [[ADDR:%.*]], ptr noundef [[VAL:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[ADDR_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[VAL_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca [[STRUCT_PS:%.*]], align 2
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    store ptr [[ADDR]], ptr [[ADDR_ADDR]], align 4
// CHECK-NEXT:    store ptr [[VAL]], ptr [[VAL_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[ADDR_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[VAL_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 2 [[DOTATOMICTMP]], ptr align 2 [[TMP1]], i32 6, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[ATOMIC_TEMP]], ptr align 2 [[DOTATOMICTMP]], i64 6, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr [[ATOMIC_TEMP]], align 8
// CHECK-NEXT:    store atomic i64 [[TMP2]], ptr [[TMP0]] seq_cst, align 8
// CHECK-NEXT:    ret void
//
void test_promoted_store(_Atomic(PS) *addr, PS *val) {
  __c11_atomic_store(addr, *val, 5);
}

// CHECK-LABEL: define dso_local arm_aapcscc void @test_promoted_exchange(
// CHECK-SAME: ptr dead_on_unwind noalias writable sret([[STRUCT_PS:%.*]]) align 2 [[AGG_RESULT:%.*]], ptr noundef [[ADDR:%.*]], ptr noundef [[VAL:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[ADDR_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[VAL_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca [[STRUCT_PS]], align 2
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    store ptr [[ADDR]], ptr [[ADDR_ADDR]], align 4
// CHECK-NEXT:    store ptr [[VAL]], ptr [[VAL_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[ADDR_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[VAL_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 2 [[DOTATOMICTMP]], ptr align 2 [[TMP1]], i32 6, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[ATOMIC_TEMP]], ptr align 2 [[DOTATOMICTMP]], i64 6, i1 false)
// CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr [[ATOMIC_TEMP]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw xchg ptr [[TMP0]], i64 [[TMP2]] seq_cst, align 8
// CHECK-NEXT:    store i64 [[TMP3]], ptr [[ATOMIC_TEMP1]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 2 [[AGG_RESULT]], ptr align 8 [[ATOMIC_TEMP1]], i32 6, i1 false)
// CHECK-NEXT:    ret void
//
PS test_promoted_exchange(_Atomic(PS) *addr, PS *val) {
  return __c11_atomic_exchange(addr, *val, 5);
}

// CHECK-LABEL: define dso_local arm_aapcscc zeroext i1 @test_promoted_cmpxchg(
// CHECK-SAME: ptr noundef [[ADDR:%.*]], ptr noundef [[DESIRED:%.*]], ptr noundef [[NEW:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[ADDR_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[DESIRED_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[NEW_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca [[STRUCT_PS:%.*]], align 2
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca { [[STRUCT_PS]], [2 x i8] }, align 8
// CHECK-NEXT:    [[CMPXCHG_BOOL:%.*]] = alloca i8, align 1
// CHECK-NEXT:    store ptr [[ADDR]], ptr [[ADDR_ADDR]], align 4
// CHECK-NEXT:    store ptr [[DESIRED]], ptr [[DESIRED_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW]], ptr [[NEW_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[ADDR_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[DESIRED_ADDR]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 2 [[DOTATOMICTMP]], ptr align 2 [[TMP2]], i32 6, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[ATOMIC_TEMP]], ptr align 2 [[TMP1]], i64 6, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[ATOMIC_TEMP1]], ptr align 2 [[DOTATOMICTMP]], i64 6, i1 false)
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i64, ptr [[ATOMIC_TEMP1]], align 8
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_8:%.*]] = call i8 @__atomic_compare_exchange_8(ptr [[TMP0]], ptr [[ATOMIC_TEMP]], i64 [[CMPXCHG_DESIRED]], i32 5, i32 5)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_8]], 0
// CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[CMPXCHG_BOOL]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP3]] to i1
// CHECK-NEXT:    ret i1 [[LOADEDV]]
//
_Bool test_promoted_cmpxchg(_Atomic(PS) *addr, PS *desired, PS *new) {
  return __c11_atomic_compare_exchange_strong(addr, desired, *new, 5, 5);
}

struct Empty {};

// CHECK-LABEL: define dso_local arm_aapcscc void @test_empty_struct_load(
// CHECK-SAME: ptr noundef [[EMPTY:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_EMPTY:%.*]], align 1
// CHECK-NEXT:    [[EMPTY_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { [[STRUCT_EMPTY]], [1 x i8] }, align 1
// CHECK-NEXT:    store ptr [[EMPTY]], ptr [[EMPTY_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[EMPTY_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load atomic i8, ptr [[TMP0]] seq_cst, align 1
// CHECK-NEXT:    store i8 [[TMP1]], ptr [[ATOMIC_TEMP]], align 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 1 [[RETVAL]], ptr align 1 [[ATOMIC_TEMP]], i32 0, i1 false)
// CHECK-NEXT:    ret void
//
struct Empty test_empty_struct_load(_Atomic(struct Empty)* empty) {
  return __c11_atomic_load(empty, 5);
}

// CHECK-LABEL: define dso_local arm_aapcscc void @test_empty_struct_store(
// CHECK-SAME: ptr noundef [[EMPTY:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[VALUE:%.*]] = alloca [[STRUCT_EMPTY:%.*]], align 1
// CHECK-NEXT:    [[EMPTY_ADDR:%.*]] = alloca ptr, align 4
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca [[STRUCT_EMPTY]], align 1
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca { [[STRUCT_EMPTY]], [1 x i8] }, align 1
// CHECK-NEXT:    store ptr [[EMPTY]], ptr [[EMPTY_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[EMPTY_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i32(ptr align 1 [[DOTATOMICTMP]], ptr align 1 [[VALUE]], i32 0, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 1 [[ATOMIC_TEMP]], ptr align 1 [[DOTATOMICTMP]], i64 0, i1 false)
// CHECK-NEXT:    [[TMP1:%.*]] = load i8, ptr [[ATOMIC_TEMP]], align 1
// CHECK-NEXT:    store atomic i8 [[TMP1]], ptr [[TMP0]] seq_cst, align 1
// CHECK-NEXT:    ret void
//
void test_empty_struct_store(_Atomic(struct Empty)* empty, struct Empty value) {
  __c11_atomic_store(empty, value, 5);
}
