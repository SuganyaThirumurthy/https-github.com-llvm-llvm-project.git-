// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// RUN: %clang_cc1 %s -std=c++11 -emit-llvm -o - -triple=x86_64-linux-gnu | FileCheck %s
// RUN: %clang_cc1 %s -std=c++11 -emit-llvm -o - -triple=x86_64-linux-gnu -target-cpu core2 | FileCheck %s --check-prefix=CORE2
// Check the atomic code generation for cpu targets w/wo cx16 support.

struct alignas(8) AM8 {
  int f1, f2;
};
AM8 m8;
// CHECK-LABEL: define dso_local i64 @_Z5load8v(
// CHECK-SAME: ) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_AM8:%.*]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load atomic i64, ptr @m8 monotonic, align 8
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[RETVAL]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret i64 [[TMP1]]
//
// CORE2-LABEL: define dso_local i64 @_Z5load8v(
// CORE2-SAME: ) #[[ATTR0:[0-9]+]] {
// CORE2-NEXT:  [[ENTRY:.*:]]
// CORE2-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_AM8:%.*]], align 8
// CORE2-NEXT:    [[TMP0:%.*]] = load atomic i64, ptr @m8 monotonic, align 8
// CORE2-NEXT:    store i64 [[TMP0]], ptr [[RETVAL]], align 8
// CORE2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[RETVAL]], align 8
// CORE2-NEXT:    ret i64 [[TMP1]]
//
AM8 load8() {
  AM8 am;
  __atomic_load(&m8, &am, 0);
  return am;
}

AM8 s8;
// CHECK-LABEL: define dso_local void @_Z6store8v(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr @s8, align 8
// CHECK-NEXT:    store atomic i64 [[TMP0]], ptr @m8 monotonic, align 8
// CHECK-NEXT:    ret void
//
// CORE2-LABEL: define dso_local void @_Z6store8v(
// CORE2-SAME: ) #[[ATTR0]] {
// CORE2-NEXT:  [[ENTRY:.*:]]
// CORE2-NEXT:    [[TMP0:%.*]] = load i64, ptr @s8, align 8
// CORE2-NEXT:    store atomic i64 [[TMP0]], ptr @m8 monotonic, align 8
// CORE2-NEXT:    ret void
//
void store8() {
  __atomic_store(&m8, &s8, 0);
}

// CHECK-LABEL: define dso_local noundef zeroext i1 @_Z8cmpxchg8v(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[AM:%.*]] = alloca [[STRUCT_AM8:%.*]], align 8
// CHECK-NEXT:    [[CMPXCHG_BOOL:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[CMPXCHG_EXPECTED:%.*]] = load i64, ptr @s8, align 8
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i64, ptr [[AM]], align 8
// CHECK-NEXT:    [[CMPXCHG_PAIR:%.*]] = cmpxchg ptr @m8, i64 [[CMPXCHG_EXPECTED]], i64 [[CMPXCHG_DESIRED]] monotonic monotonic, align 8
// CHECK-NEXT:    [[CMPXCHG_PREV:%.*]] = extractvalue { i64, i1 } [[CMPXCHG_PAIR]], 0
// CHECK-NEXT:    store i64 [[CMPXCHG_PREV]], ptr @s8, align 8
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = extractvalue { i64, i1 } [[CMPXCHG_PAIR]], 1
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[CMPXCHG_SUCCESS]] to i8
// CHECK-NEXT:    store i8 [[STOREDV]], ptr [[CMPXCHG_BOOL]], align 1
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[CMPXCHG_BOOL]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CHECK-NEXT:    ret i1 [[LOADEDV]]
//
// CORE2-LABEL: define dso_local noundef zeroext i1 @_Z8cmpxchg8v(
// CORE2-SAME: ) #[[ATTR0]] {
// CORE2-NEXT:  [[ENTRY:.*:]]
// CORE2-NEXT:    [[AM:%.*]] = alloca [[STRUCT_AM8:%.*]], align 8
// CORE2-NEXT:    [[CMPXCHG_BOOL:%.*]] = alloca i8, align 1
// CORE2-NEXT:    [[CMPXCHG_EXPECTED:%.*]] = load i64, ptr @s8, align 8
// CORE2-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i64, ptr [[AM]], align 8
// CORE2-NEXT:    [[CMPXCHG_PAIR:%.*]] = cmpxchg ptr @m8, i64 [[CMPXCHG_EXPECTED]], i64 [[CMPXCHG_DESIRED]] monotonic monotonic, align 8
// CORE2-NEXT:    [[CMPXCHG_PREV:%.*]] = extractvalue { i64, i1 } [[CMPXCHG_PAIR]], 0
// CORE2-NEXT:    store i64 [[CMPXCHG_PREV]], ptr @s8, align 8
// CORE2-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = extractvalue { i64, i1 } [[CMPXCHG_PAIR]], 1
// CORE2-NEXT:    [[STOREDV:%.*]] = zext i1 [[CMPXCHG_SUCCESS]] to i8
// CORE2-NEXT:    store i8 [[STOREDV]], ptr [[CMPXCHG_BOOL]], align 1
// CORE2-NEXT:    [[TMP0:%.*]] = load i8, ptr [[CMPXCHG_BOOL]], align 1
// CORE2-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CORE2-NEXT:    ret i1 [[LOADEDV]]
//
bool cmpxchg8() {
  AM8 am;
  return __atomic_compare_exchange(&m8, &s8, &am, 0, 0, 0);
}

struct alignas(16) AM16 {
  long f1, f2;
};

AM16 m16;
// CHECK-LABEL: define dso_local { i64, i64 } @_Z6load16v(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_AM16:%.*]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = load atomic i128, ptr @m16 monotonic, align 16
// CHECK-NEXT:    store i128 [[TMP0]], ptr [[RETVAL]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = load { i64, i64 }, ptr [[RETVAL]], align 16
// CHECK-NEXT:    ret { i64, i64 } [[TMP1]]
//
// CORE2-LABEL: define dso_local { i64, i64 } @_Z6load16v(
// CORE2-SAME: ) #[[ATTR0]] {
// CORE2-NEXT:  [[ENTRY:.*:]]
// CORE2-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_AM16:%.*]], align 16
// CORE2-NEXT:    [[TMP0:%.*]] = load atomic i128, ptr @m16 monotonic, align 16
// CORE2-NEXT:    store i128 [[TMP0]], ptr [[RETVAL]], align 16
// CORE2-NEXT:    [[TMP1:%.*]] = load { i64, i64 }, ptr [[RETVAL]], align 16
// CORE2-NEXT:    ret { i64, i64 } [[TMP1]]
//
AM16 load16() {
  AM16 am;
  __atomic_load(&m16, &am, 0);
  return am;
}

AM16 s16;
// CHECK-LABEL: define dso_local void @_Z7store16v(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[TMP0:%.*]] = load i128, ptr @s16, align 16
// CHECK-NEXT:    store atomic i128 [[TMP0]], ptr @m16 monotonic, align 16
// CHECK-NEXT:    ret void
//
// CORE2-LABEL: define dso_local void @_Z7store16v(
// CORE2-SAME: ) #[[ATTR0]] {
// CORE2-NEXT:  [[ENTRY:.*:]]
// CORE2-NEXT:    [[TMP0:%.*]] = load i128, ptr @s16, align 16
// CORE2-NEXT:    store atomic i128 [[TMP0]], ptr @m16 monotonic, align 16
// CORE2-NEXT:    ret void
//
void store16() {
  __atomic_store(&m16, &s16, 0);
}

// CHECK-LABEL: define dso_local noundef zeroext i1 @_Z9cmpxchg16v(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[AM:%.*]] = alloca [[STRUCT_AM16:%.*]], align 16
// CHECK-NEXT:    [[CMPXCHG_BOOL:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i128, ptr [[AM]], align 16
// CHECK-NEXT:    [[__ATOMIC_COMPARE_EXCHANGE_16:%.*]] = call i8 @__atomic_compare_exchange_16(ptr @m16, ptr @s16, i128 [[CMPXCHG_DESIRED]], i32 0, i32 0)
// CHECK-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = icmp eq i8 [[__ATOMIC_COMPARE_EXCHANGE_16]], 0
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[CMPXCHG_SUCCESS]] to i8
// CHECK-NEXT:    store i8 [[STOREDV]], ptr [[CMPXCHG_BOOL]], align 1
// CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[CMPXCHG_BOOL]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CHECK-NEXT:    ret i1 [[LOADEDV]]
//
// CORE2-LABEL: define dso_local noundef zeroext i1 @_Z9cmpxchg16v(
// CORE2-SAME: ) #[[ATTR0]] {
// CORE2-NEXT:  [[ENTRY:.*:]]
// CORE2-NEXT:    [[AM:%.*]] = alloca [[STRUCT_AM16:%.*]], align 16
// CORE2-NEXT:    [[CMPXCHG_BOOL:%.*]] = alloca i8, align 1
// CORE2-NEXT:    [[CMPXCHG_EXPECTED:%.*]] = load i128, ptr @s16, align 16
// CORE2-NEXT:    [[CMPXCHG_DESIRED:%.*]] = load i128, ptr [[AM]], align 16
// CORE2-NEXT:    [[CMPXCHG_PAIR:%.*]] = cmpxchg ptr @m16, i128 [[CMPXCHG_EXPECTED]], i128 [[CMPXCHG_DESIRED]] monotonic monotonic, align 16
// CORE2-NEXT:    [[CMPXCHG_PREV:%.*]] = extractvalue { i128, i1 } [[CMPXCHG_PAIR]], 0
// CORE2-NEXT:    store i128 [[CMPXCHG_PREV]], ptr @s16, align 16
// CORE2-NEXT:    [[CMPXCHG_SUCCESS:%.*]] = extractvalue { i128, i1 } [[CMPXCHG_PAIR]], 1
// CORE2-NEXT:    [[STOREDV:%.*]] = zext i1 [[CMPXCHG_SUCCESS]] to i8
// CORE2-NEXT:    store i8 [[STOREDV]], ptr [[CMPXCHG_BOOL]], align 1
// CORE2-NEXT:    [[TMP0:%.*]] = load i8, ptr [[CMPXCHG_BOOL]], align 1
// CORE2-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP0]] to i1
// CORE2-NEXT:    ret i1 [[LOADEDV]]
//
bool cmpxchg16() {
  AM16 am;
  return __atomic_compare_exchange(&m16, &s16, &am, 0, 0, 0);
}
