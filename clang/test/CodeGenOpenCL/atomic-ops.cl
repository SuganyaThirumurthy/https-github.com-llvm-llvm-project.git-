// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// RUN: %clang_cc1 %s -cl-std=CL2.0 -emit-llvm -O0 -o - -triple=amdgcn-amd-amdhsa \
// RUN:   | FileCheck %s

// Also test serialization of atomic operations here, to avoid duplicating the test.
// RUN: %clang_cc1 %s -cl-std=CL2.0 -emit-pch -O0 -o %t -triple=amdgcn-amd-amdhsa
// RUN: %clang_cc1 %s -cl-std=CL2.0 -include-pch %t -O0 -triple=amdgcn-amd-amdhsa \
// RUN:   -emit-llvm -o - | FileCheck %s

#ifndef ALREADY_INCLUDED
#define ALREADY_INCLUDED

#pragma OPENCL EXTENSION cl_khr_int64_base_atomics : enable
#pragma OPENCL EXTENSION cl_khr_int64_extended_atomics : enable

typedef __INTPTR_TYPE__ intptr_t;
typedef int int8 __attribute__((ext_vector_type(8)));

typedef enum memory_order {
  memory_order_relaxed = __ATOMIC_RELAXED,
  memory_order_acquire = __ATOMIC_ACQUIRE,
  memory_order_release = __ATOMIC_RELEASE,
  memory_order_acq_rel = __ATOMIC_ACQ_REL,
  memory_order_seq_cst = __ATOMIC_SEQ_CST
} memory_order;

typedef enum memory_scope {
  memory_scope_work_item = __OPENCL_MEMORY_SCOPE_WORK_ITEM,
  memory_scope_work_group = __OPENCL_MEMORY_SCOPE_WORK_GROUP,
  memory_scope_device = __OPENCL_MEMORY_SCOPE_DEVICE,
  memory_scope_all_svm_devices = __OPENCL_MEMORY_SCOPE_ALL_SVM_DEVICES,
#if defined(cl_intel_subgroups) || defined(cl_khr_subgroups)
  memory_scope_sub_group = __OPENCL_MEMORY_SCOPE_SUB_GROUP
#endif
} memory_scope;

atomic_int j;

// CHECK-LABEL: define dso_local void @fi1(
// CHECK-SAME: ptr noundef [[I:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[X:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP1:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP3:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[I_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[I_ADDR]] to ptr
// CHECK-NEXT:    [[X_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[X]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP1_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP1]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP2_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP2]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP3_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP3]] to ptr
// CHECK-NEXT:    store ptr [[I]], ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP2]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load atomic i32, ptr [[TMP3]] syncscope("agent") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP4]], ptr [[ATOMIC_TEMP1_ASCAST]], align 4
// CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[ATOMIC_TEMP1_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP5]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load atomic i32, ptr [[TMP6]] seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP7]], ptr [[ATOMIC_TEMP2_ASCAST]], align 4
// CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[ATOMIC_TEMP2_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP8]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = load atomic i32, ptr [[TMP9]] syncscope("wavefront") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP10]], ptr [[ATOMIC_TEMP3_ASCAST]], align 4
// CHECK-NEXT:    [[TMP11:%.*]] = load i32, ptr [[ATOMIC_TEMP3_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP11]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    ret void
//
void fi1(atomic_int *i) {
  int x = __opencl_atomic_load(i, memory_order_seq_cst, memory_scope_work_group);

  x = __opencl_atomic_load(i, memory_order_seq_cst, memory_scope_device);

  x = __opencl_atomic_load(i, memory_order_seq_cst, memory_scope_all_svm_devices);

  x = __opencl_atomic_load(i, memory_order_seq_cst, memory_scope_sub_group);
}

// CHECK-LABEL: define dso_local void @fi2(
// CHECK-SAME: ptr noundef [[I:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[I_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[I_ADDR]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    store ptr [[I]], ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    store atomic i32 [[TMP1]], ptr [[TMP0]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    ret void
//
void fi2(atomic_int *i) {
  __opencl_atomic_store(i, 1, memory_order_seq_cst, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local void @test_addr(
// CHECK-SAME: ptr addrspace(1) noundef [[IG:%.*]], ptr addrspace(5) noundef [[IP:%.*]], ptr addrspace(3) noundef [[IL:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[IG_ADDR:%.*]] = alloca ptr addrspace(1), align 8, addrspace(5)
// CHECK-NEXT:    [[IP_ADDR:%.*]] = alloca ptr addrspace(5), align 4, addrspace(5)
// CHECK-NEXT:    [[IL_ADDR:%.*]] = alloca ptr addrspace(3), align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP1:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP2:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[IG_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[IG_ADDR]] to ptr
// CHECK-NEXT:    [[IP_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[IP_ADDR]] to ptr
// CHECK-NEXT:    [[IL_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[IL_ADDR]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP1_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP1]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP2_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP2]] to ptr
// CHECK-NEXT:    store ptr addrspace(1) [[IG]], ptr [[IG_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store ptr addrspace(5) [[IP]], ptr [[IP_ADDR_ASCAST]], align 4
// CHECK-NEXT:    store ptr addrspace(3) [[IL]], ptr [[IL_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(1), ptr [[IG_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    store atomic i32 [[TMP1]], ptr addrspace(1) [[TMP0]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr addrspace(5), ptr [[IP_ADDR_ASCAST]], align 4
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP1_ASCAST]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTATOMICTMP1_ASCAST]], align 4
// CHECK-NEXT:    store atomic i32 [[TMP3]], ptr addrspace(5) [[TMP2]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr addrspace(3), ptr [[IL_ADDR_ASCAST]], align 4
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP2_ASCAST]], align 4
// CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTATOMICTMP2_ASCAST]], align 4
// CHECK-NEXT:    store atomic i32 [[TMP5]], ptr addrspace(3) [[TMP4]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    ret void
//
void test_addr(global atomic_int *ig, private atomic_int *ip, local atomic_int *il) {
  __opencl_atomic_store(ig, 1, memory_order_seq_cst, memory_scope_work_group);

  __opencl_atomic_store(ip, 1, memory_order_seq_cst, memory_scope_work_group);

  __opencl_atomic_store(il, 1, memory_order_seq_cst, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local void @fi3(
// CHECK-SAME: ptr noundef [[I:%.*]], ptr noundef [[UI:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[UI_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[X:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP1:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP2:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP3:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP4:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP5:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP6:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP7:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP8:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[I_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[I_ADDR]] to ptr
// CHECK-NEXT:    [[UI_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[UI_ADDR]] to ptr
// CHECK-NEXT:    [[X_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[X]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP1_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP1]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP2_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP2]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP3_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP3]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP4_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP4]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP5_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP5]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP6_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP6]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP7_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP7]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP8_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP8]] to ptr
// CHECK-NEXT:    store ptr [[I]], ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store ptr [[UI]], ptr [[UI_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = atomicrmw and ptr [[TMP0]], i32 [[TMP1]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP2]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP3]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP1_ASCAST]], align 4
// CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTATOMICTMP1_ASCAST]], align 4
// CHECK-NEXT:    [[TMP6:%.*]] = atomicrmw min ptr [[TMP4]], i32 [[TMP5]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP6]], ptr [[ATOMIC_TEMP2_ASCAST]], align 4
// CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[ATOMIC_TEMP2_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP7]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP3_ASCAST]], align 4
// CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTATOMICTMP3_ASCAST]], align 4
// CHECK-NEXT:    [[TMP10:%.*]] = atomicrmw max ptr [[TMP8]], i32 [[TMP9]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP10]], ptr [[ATOMIC_TEMP4_ASCAST]], align 4
// CHECK-NEXT:    [[TMP11:%.*]] = load i32, ptr [[ATOMIC_TEMP4_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP11]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    [[TMP12:%.*]] = load ptr, ptr [[UI_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP5_ASCAST]], align 4
// CHECK-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DOTATOMICTMP5_ASCAST]], align 4
// CHECK-NEXT:    [[TMP14:%.*]] = atomicrmw umin ptr [[TMP12]], i32 [[TMP13]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP14]], ptr [[ATOMIC_TEMP6_ASCAST]], align 4
// CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[ATOMIC_TEMP6_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP15]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    [[TMP16:%.*]] = load ptr, ptr [[UI_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP7_ASCAST]], align 4
// CHECK-NEXT:    [[TMP17:%.*]] = load i32, ptr [[DOTATOMICTMP7_ASCAST]], align 4
// CHECK-NEXT:    [[TMP18:%.*]] = atomicrmw umax ptr [[TMP16]], i32 [[TMP17]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP18]], ptr [[ATOMIC_TEMP8_ASCAST]], align 4
// CHECK-NEXT:    [[TMP19:%.*]] = load i32, ptr [[ATOMIC_TEMP8_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP19]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    ret void
//
void fi3(atomic_int *i, atomic_uint *ui) {
  int x = __opencl_atomic_fetch_and(i, 1, memory_order_seq_cst, memory_scope_work_group);

  x = __opencl_atomic_fetch_min(i, 1, memory_order_seq_cst, memory_scope_work_group);

  x = __opencl_atomic_fetch_max(i, 1, memory_order_seq_cst, memory_scope_work_group);

  x = __opencl_atomic_fetch_min(ui, 1, memory_order_seq_cst, memory_scope_work_group);

  x = __opencl_atomic_fetch_max(ui, 1, memory_order_seq_cst, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local zeroext i1 @fi4(
// CHECK-SAME: ptr noundef [[I:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca i1, align 1, addrspace(5)
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[CMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[CMPXCHG_BOOL:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[RETVAL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[RETVAL]] to ptr
// CHECK-NEXT:    [[I_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[I_ADDR]] to ptr
// CHECK-NEXT:    [[CMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[CMP]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    [[CMPXCHG_BOOL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[CMPXCHG_BOOL]] to ptr
// CHECK-NEXT:    store ptr [[I]], ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 0, ptr [[CMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 1, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[CMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP1]], i32 [[TMP2]] syncscope("workgroup-one-as") acquire acquire, align 4
// CHECK-NEXT:    [[TMP4:%.*]] = extractvalue { i32, i1 } [[TMP3]], 0
// CHECK-NEXT:    [[TMP5:%.*]] = extractvalue { i32, i1 } [[TMP3]], 1
// CHECK-NEXT:    br i1 [[TMP5]], label %[[CMPXCHG_CONTINUE:.*]], label %[[CMPXCHG_STORE_EXPECTED:.*]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED]]:
// CHECK-NEXT:    store i32 [[TMP4]], ptr [[CMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE]]
// CHECK:       [[CMPXCHG_CONTINUE]]:
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[TMP5]] to i8
// CHECK-NEXT:    store i8 [[STOREDV]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP6]] to i1
// CHECK-NEXT:    ret i1 [[LOADEDV]]
//
bool fi4(atomic_int *i) {
  int cmp = 0;
  return __opencl_atomic_compare_exchange_strong(i, &cmp, 1, memory_order_acquire, memory_order_acquire, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local void @fi5(
// CHECK-SAME: ptr noundef [[I:%.*]], i32 noundef [[SCOPE:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[SCOPE_ADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[X:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[I_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[I_ADDR]] to ptr
// CHECK-NEXT:    [[SCOPE_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[SCOPE_ADDR]] to ptr
// CHECK-NEXT:    [[X_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[X]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    store ptr [[I]], ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 [[SCOPE]], ptr [[SCOPE_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[SCOPE_ADDR_ASCAST]], align 4
// CHECK-NEXT:    switch i32 [[TMP1]], label %[[OPENCL_ALLSVMDEVICES:.*]] [
// CHECK-NEXT:      i32 1, label %[[OPENCL_WORKGROUP:.*]]
// CHECK-NEXT:      i32 2, label %[[OPENCL_DEVICE:.*]]
// CHECK-NEXT:      i32 4, label %[[OPENCL_SUBGROUP:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[OPENCL_WORKGROUP]]:
// CHECK-NEXT:    [[TMP2:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP2]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE:.*]]
// CHECK:       [[OPENCL_DEVICE]]:
// CHECK-NEXT:    [[TMP3:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("agent") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP3]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE]]
// CHECK:       [[OPENCL_ALLSVMDEVICES]]:
// CHECK-NEXT:    [[TMP4:%.*]] = load atomic i32, ptr [[TMP0]] seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP4]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE]]
// CHECK:       [[OPENCL_SUBGROUP]]:
// CHECK-NEXT:    [[TMP5:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("wavefront") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP5]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE]]
// CHECK:       [[ATOMIC_SCOPE_CONTINUE]]:
// CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP6]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    ret void
//
void fi5(atomic_int *i, int scope) {
  int x = __opencl_atomic_load(i, memory_order_seq_cst, scope);
}

// CHECK-LABEL: define dso_local void @fi6(
// CHECK-SAME: ptr noundef [[I:%.*]], i32 noundef [[ORDER:%.*]], i32 noundef [[SCOPE:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[ORDER_ADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[SCOPE_ADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[X:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[I_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[I_ADDR]] to ptr
// CHECK-NEXT:    [[ORDER_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ORDER_ADDR]] to ptr
// CHECK-NEXT:    [[SCOPE_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[SCOPE_ADDR]] to ptr
// CHECK-NEXT:    [[X_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[X]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    store ptr [[I]], ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 [[ORDER]], ptr [[ORDER_ADDR_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[SCOPE]], ptr [[SCOPE_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[ORDER_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[SCOPE_ADDR_ASCAST]], align 4
// CHECK-NEXT:    switch i32 [[TMP1]], label %[[MONOTONIC:.*]] [
// CHECK-NEXT:      i32 1, label %[[ACQUIRE:.*]]
// CHECK-NEXT:      i32 2, label %[[ACQUIRE]]
// CHECK-NEXT:      i32 5, label %[[SEQCST:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[MONOTONIC]]:
// CHECK-NEXT:    switch i32 [[TMP2]], label %[[OPENCL_ALLSVMDEVICES:.*]] [
// CHECK-NEXT:      i32 1, label %[[OPENCL_WORKGROUP:.*]]
// CHECK-NEXT:      i32 2, label %[[OPENCL_DEVICE:.*]]
// CHECK-NEXT:      i32 4, label %[[OPENCL_SUBGROUP:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[ACQUIRE]]:
// CHECK-NEXT:    switch i32 [[TMP2]], label %[[OPENCL_ALLSVMDEVICES3:.*]] [
// CHECK-NEXT:      i32 1, label %[[OPENCL_WORKGROUP1:.*]]
// CHECK-NEXT:      i32 2, label %[[OPENCL_DEVICE2:.*]]
// CHECK-NEXT:      i32 4, label %[[OPENCL_SUBGROUP4:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[SEQCST]]:
// CHECK-NEXT:    switch i32 [[TMP2]], label %[[OPENCL_ALLSVMDEVICES8:.*]] [
// CHECK-NEXT:      i32 1, label %[[OPENCL_WORKGROUP6:.*]]
// CHECK-NEXT:      i32 2, label %[[OPENCL_DEVICE7:.*]]
// CHECK-NEXT:      i32 4, label %[[OPENCL_SUBGROUP9:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[ATOMIC_CONTINUE:.*]]:
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[TMP3]], ptr [[X_ASCAST]], align 4
// CHECK-NEXT:    ret void
// CHECK:       [[OPENCL_WORKGROUP]]:
// CHECK-NEXT:    [[TMP4:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("workgroup-one-as") monotonic, align 4
// CHECK-NEXT:    store i32 [[TMP4]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE:.*]]
// CHECK:       [[OPENCL_DEVICE]]:
// CHECK-NEXT:    [[TMP5:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("agent-one-as") monotonic, align 4
// CHECK-NEXT:    store i32 [[TMP5]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE]]
// CHECK:       [[OPENCL_ALLSVMDEVICES]]:
// CHECK-NEXT:    [[TMP6:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("one-as") monotonic, align 4
// CHECK-NEXT:    store i32 [[TMP6]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE]]
// CHECK:       [[OPENCL_SUBGROUP]]:
// CHECK-NEXT:    [[TMP7:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("wavefront-one-as") monotonic, align 4
// CHECK-NEXT:    store i32 [[TMP7]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE]]
// CHECK:       [[ATOMIC_SCOPE_CONTINUE]]:
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE]]
// CHECK:       [[OPENCL_WORKGROUP1]]:
// CHECK-NEXT:    [[TMP8:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("workgroup-one-as") acquire, align 4
// CHECK-NEXT:    store i32 [[TMP8]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE5:.*]]
// CHECK:       [[OPENCL_DEVICE2]]:
// CHECK-NEXT:    [[TMP9:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("agent-one-as") acquire, align 4
// CHECK-NEXT:    store i32 [[TMP9]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE5]]
// CHECK:       [[OPENCL_ALLSVMDEVICES3]]:
// CHECK-NEXT:    [[TMP10:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("one-as") acquire, align 4
// CHECK-NEXT:    store i32 [[TMP10]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE5]]
// CHECK:       [[OPENCL_SUBGROUP4]]:
// CHECK-NEXT:    [[TMP11:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("wavefront-one-as") acquire, align 4
// CHECK-NEXT:    store i32 [[TMP11]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE5]]
// CHECK:       [[ATOMIC_SCOPE_CONTINUE5]]:
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE]]
// CHECK:       [[OPENCL_WORKGROUP6]]:
// CHECK-NEXT:    [[TMP12:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP12]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE10:.*]]
// CHECK:       [[OPENCL_DEVICE7]]:
// CHECK-NEXT:    [[TMP13:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("agent") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP13]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE10]]
// CHECK:       [[OPENCL_ALLSVMDEVICES8]]:
// CHECK-NEXT:    [[TMP14:%.*]] = load atomic i32, ptr [[TMP0]] seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP14]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE10]]
// CHECK:       [[OPENCL_SUBGROUP9]]:
// CHECK-NEXT:    [[TMP15:%.*]] = load atomic i32, ptr [[TMP0]] syncscope("wavefront") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP15]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    br label %[[ATOMIC_SCOPE_CONTINUE10]]
// CHECK:       [[ATOMIC_SCOPE_CONTINUE10]]:
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE]]
//
void fi6(atomic_int *i, int order, int scope) {
  int x = __opencl_atomic_load(i, order, scope);
}

// CHECK-LABEL: define dso_local float @ff1(
// CHECK-SAME: ptr addrspace(1) noundef [[D:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[D_ADDR:%.*]] = alloca ptr addrspace(1), align 8, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[RETVAL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[RETVAL]] to ptr
// CHECK-NEXT:    [[D_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[D_ADDR]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    store ptr addrspace(1) [[D]], ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(1), ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load atomic i32, ptr addrspace(1) [[TMP0]] syncscope("workgroup-one-as") monotonic, align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load float, ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    ret float [[TMP2]]
//
float ff1(global atomic_float *d) {
  return __opencl_atomic_load(d, memory_order_relaxed, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local void @ff2(
// CHECK-SAME: ptr noundef [[D:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[D_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[D_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[D_ADDR]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    store ptr [[D]], ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store float 1.000000e+00, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    store atomic i32 [[TMP1]], ptr [[TMP0]] syncscope("workgroup-one-as") release, align 4
// CHECK-NEXT:    ret void
//
void ff2(atomic_float *d) {
  __opencl_atomic_store(d, 1, memory_order_release, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local float @ff3(
// CHECK-SAME: ptr noundef [[D:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[D_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[RETVAL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[RETVAL]] to ptr
// CHECK-NEXT:    [[D_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[D_ADDR]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    store ptr [[D]], ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store float 2.000000e+00, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = atomicrmw xchg ptr [[TMP0]], i32 [[TMP1]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP2]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load float, ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    ret float [[TMP3]]
//
float ff3(atomic_float *d) {
  return __opencl_atomic_exchange(d, 2, memory_order_seq_cst, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local float @ff4(
// CHECK-SAME: ptr addrspace(1) noundef [[D:%.*]], float noundef [[A:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[D_ADDR:%.*]] = alloca ptr addrspace(1), align 8, addrspace(5)
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[RETVAL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[RETVAL]] to ptr
// CHECK-NEXT:    [[D_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[D_ADDR]] to ptr
// CHECK-NEXT:    [[A_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[A_ADDR]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    store ptr addrspace(1) [[D]], ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store float [[A]], ptr [[A_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(1), ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load float, ptr [[A_ADDR_ASCAST]], align 4
// CHECK-NEXT:    store float [[TMP1]], ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load float, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw fadd ptr addrspace(1) [[TMP0]], float [[TMP2]] syncscope("workgroup-one-as") monotonic, align 4
// CHECK-NEXT:    store float [[TMP3]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP4:%.*]] = load float, ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    ret float [[TMP4]]
//
float ff4(global atomic_float *d, float a) {
  return __opencl_atomic_fetch_add(d, a, memory_order_relaxed, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local float @ff5(
// CHECK-SAME: ptr addrspace(1) noundef [[D:%.*]], double noundef [[A:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[D_ADDR:%.*]] = alloca ptr addrspace(1), align 8, addrspace(5)
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca double, align 8, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca double, align 8, addrspace(5)
// CHECK-NEXT:    [[RETVAL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[RETVAL]] to ptr
// CHECK-NEXT:    [[D_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[D_ADDR]] to ptr
// CHECK-NEXT:    [[A_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[A_ADDR]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    store ptr addrspace(1) [[D]], ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store double [[A]], ptr [[A_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(1), ptr [[D_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load double, ptr [[A_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store double [[TMP1]], ptr [[DOTATOMICTMP_ASCAST]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load double, ptr [[DOTATOMICTMP_ASCAST]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw fadd ptr addrspace(1) [[TMP0]], double [[TMP2]] syncscope("workgroup-one-as") monotonic, align 8
// CHECK-NEXT:    store double [[TMP3]], ptr [[ATOMIC_TEMP_ASCAST]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load double, ptr [[ATOMIC_TEMP_ASCAST]], align 8
// CHECK-NEXT:    [[CONV:%.*]] = fptrunc double [[TMP4]] to float
// CHECK-NEXT:    ret float [[CONV]]
//
float ff5(global atomic_double *d, double a) {
  return __opencl_atomic_fetch_add(d, a, memory_order_relaxed, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local void @atomic_init_foo(
// CHECK-SAME: ) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    store i32 42, ptr addrspace(1) @j, align 4
// CHECK-NEXT:    ret void
//
void atomic_init_foo()
{
  __opencl_atomic_init(&j, 42);

}

// CHECK-LABEL: define dso_local void @failureOrder(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[PTR2:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[PTR2_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[CMPXCHG_BOOL:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP1:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[CMPXCHG_BOOL2:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[PTR_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[PTR_ADDR]] to ptr
// CHECK-NEXT:    [[PTR2_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[PTR2_ADDR]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    [[CMPXCHG_BOOL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[CMPXCHG_BOOL]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP1_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP1]] to ptr
// CHECK-NEXT:    [[CMPXCHG_BOOL2_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[CMPXCHG_BOOL2]] to ptr
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store ptr [[PTR2]], ptr [[PTR2_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[PTR2_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 43, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP1]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP4:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP2]], i32 [[TMP3]] syncscope("workgroup-one-as") acquire monotonic, align 4
// CHECK-NEXT:    [[TMP5:%.*]] = extractvalue { i32, i1 } [[TMP4]], 0
// CHECK-NEXT:    [[TMP6:%.*]] = extractvalue { i32, i1 } [[TMP4]], 1
// CHECK-NEXT:    br i1 [[TMP6]], label %[[CMPXCHG_CONTINUE:.*]], label %[[CMPXCHG_STORE_EXPECTED:.*]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED]]:
// CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP1]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE]]
// CHECK:       [[CMPXCHG_CONTINUE]]:
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[TMP6]] to i8
// CHECK-NEXT:    store i8 [[STOREDV]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP7]] to i1
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[PTR2_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 43, ptr [[DOTATOMICTMP1_ASCAST]], align 4
// CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP9]], align 4
// CHECK-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTATOMICTMP1_ASCAST]], align 4
// CHECK-NEXT:    [[TMP12:%.*]] = cmpxchg weak ptr [[TMP8]], i32 [[TMP10]], i32 [[TMP11]] syncscope("workgroup") seq_cst acquire, align 4
// CHECK-NEXT:    [[TMP13:%.*]] = extractvalue { i32, i1 } [[TMP12]], 0
// CHECK-NEXT:    [[TMP14:%.*]] = extractvalue { i32, i1 } [[TMP12]], 1
// CHECK-NEXT:    br i1 [[TMP14]], label %[[CMPXCHG_CONTINUE4:.*]], label %[[CMPXCHG_STORE_EXPECTED3:.*]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED3]]:
// CHECK-NEXT:    store i32 [[TMP13]], ptr [[TMP9]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE4]]
// CHECK:       [[CMPXCHG_CONTINUE4]]:
// CHECK-NEXT:    [[STOREDV5:%.*]] = zext i1 [[TMP14]] to i8
// CHECK-NEXT:    store i8 [[STOREDV5]], ptr [[CMPXCHG_BOOL2_ASCAST]], align 1
// CHECK-NEXT:    [[TMP15:%.*]] = load i8, ptr [[CMPXCHG_BOOL2_ASCAST]], align 1
// CHECK-NEXT:    [[LOADEDV6:%.*]] = trunc i8 [[TMP15]] to i1
// CHECK-NEXT:    ret void
//
void failureOrder(atomic_int *ptr, int *ptr2) {
  __opencl_atomic_compare_exchange_strong(ptr, ptr2, 43, memory_order_acquire, memory_order_relaxed, memory_scope_work_group);

  __opencl_atomic_compare_exchange_weak(ptr, ptr2, 43, memory_order_seq_cst, memory_order_acquire, memory_scope_work_group);
}

// CHECK-LABEL: define dso_local void @generalFailureOrder(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[PTR2:%.*]], i32 noundef [[SUCCESS:%.*]], i32 noundef [[FAIL:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[PTR2_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[SUCCESS_ADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[FAIL_ADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTATOMICTMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[CMPXCHG_BOOL:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[PTR_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[PTR_ADDR]] to ptr
// CHECK-NEXT:    [[PTR2_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[PTR2_ADDR]] to ptr
// CHECK-NEXT:    [[SUCCESS_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[SUCCESS_ADDR]] to ptr
// CHECK-NEXT:    [[FAIL_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[FAIL_ADDR]] to ptr
// CHECK-NEXT:    [[DOTATOMICTMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTATOMICTMP]] to ptr
// CHECK-NEXT:    [[CMPXCHG_BOOL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[CMPXCHG_BOOL]] to ptr
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store ptr [[PTR2]], ptr [[PTR2_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 [[SUCCESS]], ptr [[SUCCESS_ADDR_ASCAST]], align 4
// CHECK-NEXT:    store i32 [[FAIL]], ptr [[FAIL_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[SUCCESS_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[PTR2_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store i32 42, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[FAIL_ADDR_ASCAST]], align 4
// CHECK-NEXT:    switch i32 [[TMP1]], label %[[MONOTONIC:.*]] [
// CHECK-NEXT:      i32 1, label %[[ACQUIRE:.*]]
// CHECK-NEXT:      i32 2, label %[[ACQUIRE]]
// CHECK-NEXT:      i32 3, label %[[RELEASE:.*]]
// CHECK-NEXT:      i32 4, label %[[ACQREL:.*]]
// CHECK-NEXT:      i32 5, label %[[SEQCST:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[MONOTONIC]]:
// CHECK-NEXT:    switch i32 [[TMP3]], label %[[MONOTONIC_FAIL:.*]] [
// CHECK-NEXT:      i32 1, label %[[ACQUIRE_FAIL:.*]]
// CHECK-NEXT:      i32 2, label %[[ACQUIRE_FAIL]]
// CHECK-NEXT:      i32 5, label %[[SEQCST_FAIL:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[ACQUIRE]]:
// CHECK-NEXT:    switch i32 [[TMP3]], label %[[MONOTONIC_FAIL8:.*]] [
// CHECK-NEXT:      i32 1, label %[[ACQUIRE_FAIL9:.*]]
// CHECK-NEXT:      i32 2, label %[[ACQUIRE_FAIL9]]
// CHECK-NEXT:      i32 5, label %[[SEQCST_FAIL10:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[RELEASE]]:
// CHECK-NEXT:    switch i32 [[TMP3]], label %[[MONOTONIC_FAIL21:.*]] [
// CHECK-NEXT:      i32 1, label %[[ACQUIRE_FAIL22:.*]]
// CHECK-NEXT:      i32 2, label %[[ACQUIRE_FAIL22]]
// CHECK-NEXT:      i32 5, label %[[SEQCST_FAIL23:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[ACQREL]]:
// CHECK-NEXT:    switch i32 [[TMP3]], label %[[MONOTONIC_FAIL34:.*]] [
// CHECK-NEXT:      i32 1, label %[[ACQUIRE_FAIL35:.*]]
// CHECK-NEXT:      i32 2, label %[[ACQUIRE_FAIL35]]
// CHECK-NEXT:      i32 5, label %[[SEQCST_FAIL36:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[SEQCST]]:
// CHECK-NEXT:    switch i32 [[TMP3]], label %[[MONOTONIC_FAIL47:.*]] [
// CHECK-NEXT:      i32 1, label %[[ACQUIRE_FAIL48:.*]]
// CHECK-NEXT:      i32 2, label %[[ACQUIRE_FAIL48]]
// CHECK-NEXT:      i32 5, label %[[SEQCST_FAIL49:.*]]
// CHECK-NEXT:    ]
// CHECK:       [[ATOMIC_CONTINUE:.*]]:
// CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    [[LOADEDV:%.*]] = trunc i8 [[TMP4]] to i1
// CHECK-NEXT:    ret void
// CHECK:       [[MONOTONIC_FAIL]]:
// CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP7:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP5]], i32 [[TMP6]] syncscope("workgroup-one-as") monotonic monotonic, align 4
// CHECK-NEXT:    [[TMP8:%.*]] = extractvalue { i32, i1 } [[TMP7]], 0
// CHECK-NEXT:    [[TMP9:%.*]] = extractvalue { i32, i1 } [[TMP7]], 1
// CHECK-NEXT:    br i1 [[TMP9]], label %[[CMPXCHG_CONTINUE:.*]], label %[[CMPXCHG_STORE_EXPECTED:.*]]
// CHECK:       [[ACQUIRE_FAIL]]:
// CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP12:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP10]], i32 [[TMP11]] syncscope("workgroup-one-as") monotonic acquire, align 4
// CHECK-NEXT:    [[TMP13:%.*]] = extractvalue { i32, i1 } [[TMP12]], 0
// CHECK-NEXT:    [[TMP14:%.*]] = extractvalue { i32, i1 } [[TMP12]], 1
// CHECK-NEXT:    br i1 [[TMP14]], label %[[CMPXCHG_CONTINUE3:.*]], label %[[CMPXCHG_STORE_EXPECTED2:.*]]
// CHECK:       [[SEQCST_FAIL]]:
// CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP17:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP15]], i32 [[TMP16]] syncscope("workgroup-one-as") monotonic seq_cst, align 4
// CHECK-NEXT:    [[TMP18:%.*]] = extractvalue { i32, i1 } [[TMP17]], 0
// CHECK-NEXT:    [[TMP19:%.*]] = extractvalue { i32, i1 } [[TMP17]], 1
// CHECK-NEXT:    br i1 [[TMP19]], label %[[CMPXCHG_CONTINUE6:.*]], label %[[CMPXCHG_STORE_EXPECTED5:.*]]
// CHECK:       [[ATOMIC_CONTINUE1:.*]]:
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED]]:
// CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE]]
// CHECK:       [[CMPXCHG_CONTINUE]]:
// CHECK-NEXT:    [[STOREDV:%.*]] = zext i1 [[TMP9]] to i8
// CHECK-NEXT:    store i8 [[STOREDV]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE1]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED2]]:
// CHECK-NEXT:    store i32 [[TMP13]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE3]]
// CHECK:       [[CMPXCHG_CONTINUE3]]:
// CHECK-NEXT:    [[STOREDV4:%.*]] = zext i1 [[TMP14]] to i8
// CHECK-NEXT:    store i8 [[STOREDV4]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE1]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED5]]:
// CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE6]]
// CHECK:       [[CMPXCHG_CONTINUE6]]:
// CHECK-NEXT:    [[STOREDV7:%.*]] = zext i1 [[TMP19]] to i8
// CHECK-NEXT:    store i8 [[STOREDV7]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE1]]
// CHECK:       [[MONOTONIC_FAIL8]]:
// CHECK-NEXT:    [[TMP20:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP22:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP20]], i32 [[TMP21]] syncscope("workgroup-one-as") acquire monotonic, align 4
// CHECK-NEXT:    [[TMP23:%.*]] = extractvalue { i32, i1 } [[TMP22]], 0
// CHECK-NEXT:    [[TMP24:%.*]] = extractvalue { i32, i1 } [[TMP22]], 1
// CHECK-NEXT:    br i1 [[TMP24]], label %[[CMPXCHG_CONTINUE13:.*]], label %[[CMPXCHG_STORE_EXPECTED12:.*]]
// CHECK:       [[ACQUIRE_FAIL9]]:
// CHECK-NEXT:    [[TMP25:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP26:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP27:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP25]], i32 [[TMP26]] syncscope("workgroup-one-as") acquire acquire, align 4
// CHECK-NEXT:    [[TMP28:%.*]] = extractvalue { i32, i1 } [[TMP27]], 0
// CHECK-NEXT:    [[TMP29:%.*]] = extractvalue { i32, i1 } [[TMP27]], 1
// CHECK-NEXT:    br i1 [[TMP29]], label %[[CMPXCHG_CONTINUE16:.*]], label %[[CMPXCHG_STORE_EXPECTED15:.*]]
// CHECK:       [[SEQCST_FAIL10]]:
// CHECK-NEXT:    [[TMP30:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP31:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP32:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP30]], i32 [[TMP31]] syncscope("workgroup-one-as") acquire seq_cst, align 4
// CHECK-NEXT:    [[TMP33:%.*]] = extractvalue { i32, i1 } [[TMP32]], 0
// CHECK-NEXT:    [[TMP34:%.*]] = extractvalue { i32, i1 } [[TMP32]], 1
// CHECK-NEXT:    br i1 [[TMP34]], label %[[CMPXCHG_CONTINUE19:.*]], label %[[CMPXCHG_STORE_EXPECTED18:.*]]
// CHECK:       [[ATOMIC_CONTINUE11:.*]]:
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED12]]:
// CHECK-NEXT:    store i32 [[TMP23]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE13]]
// CHECK:       [[CMPXCHG_CONTINUE13]]:
// CHECK-NEXT:    [[STOREDV14:%.*]] = zext i1 [[TMP24]] to i8
// CHECK-NEXT:    store i8 [[STOREDV14]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE11]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED15]]:
// CHECK-NEXT:    store i32 [[TMP28]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE16]]
// CHECK:       [[CMPXCHG_CONTINUE16]]:
// CHECK-NEXT:    [[STOREDV17:%.*]] = zext i1 [[TMP29]] to i8
// CHECK-NEXT:    store i8 [[STOREDV17]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE11]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED18]]:
// CHECK-NEXT:    store i32 [[TMP33]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE19]]
// CHECK:       [[CMPXCHG_CONTINUE19]]:
// CHECK-NEXT:    [[STOREDV20:%.*]] = zext i1 [[TMP34]] to i8
// CHECK-NEXT:    store i8 [[STOREDV20]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE11]]
// CHECK:       [[MONOTONIC_FAIL21]]:
// CHECK-NEXT:    [[TMP35:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP36:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP37:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP35]], i32 [[TMP36]] syncscope("workgroup-one-as") release monotonic, align 4
// CHECK-NEXT:    [[TMP38:%.*]] = extractvalue { i32, i1 } [[TMP37]], 0
// CHECK-NEXT:    [[TMP39:%.*]] = extractvalue { i32, i1 } [[TMP37]], 1
// CHECK-NEXT:    br i1 [[TMP39]], label %[[CMPXCHG_CONTINUE26:.*]], label %[[CMPXCHG_STORE_EXPECTED25:.*]]
// CHECK:       [[ACQUIRE_FAIL22]]:
// CHECK-NEXT:    [[TMP40:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP41:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP42:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP40]], i32 [[TMP41]] syncscope("workgroup-one-as") release acquire, align 4
// CHECK-NEXT:    [[TMP43:%.*]] = extractvalue { i32, i1 } [[TMP42]], 0
// CHECK-NEXT:    [[TMP44:%.*]] = extractvalue { i32, i1 } [[TMP42]], 1
// CHECK-NEXT:    br i1 [[TMP44]], label %[[CMPXCHG_CONTINUE29:.*]], label %[[CMPXCHG_STORE_EXPECTED28:.*]]
// CHECK:       [[SEQCST_FAIL23]]:
// CHECK-NEXT:    [[TMP45:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP46:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP47:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP45]], i32 [[TMP46]] syncscope("workgroup-one-as") release seq_cst, align 4
// CHECK-NEXT:    [[TMP48:%.*]] = extractvalue { i32, i1 } [[TMP47]], 0
// CHECK-NEXT:    [[TMP49:%.*]] = extractvalue { i32, i1 } [[TMP47]], 1
// CHECK-NEXT:    br i1 [[TMP49]], label %[[CMPXCHG_CONTINUE32:.*]], label %[[CMPXCHG_STORE_EXPECTED31:.*]]
// CHECK:       [[ATOMIC_CONTINUE24:.*]]:
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED25]]:
// CHECK-NEXT:    store i32 [[TMP38]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE26]]
// CHECK:       [[CMPXCHG_CONTINUE26]]:
// CHECK-NEXT:    [[STOREDV27:%.*]] = zext i1 [[TMP39]] to i8
// CHECK-NEXT:    store i8 [[STOREDV27]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE24]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED28]]:
// CHECK-NEXT:    store i32 [[TMP43]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE29]]
// CHECK:       [[CMPXCHG_CONTINUE29]]:
// CHECK-NEXT:    [[STOREDV30:%.*]] = zext i1 [[TMP44]] to i8
// CHECK-NEXT:    store i8 [[STOREDV30]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE24]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED31]]:
// CHECK-NEXT:    store i32 [[TMP48]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE32]]
// CHECK:       [[CMPXCHG_CONTINUE32]]:
// CHECK-NEXT:    [[STOREDV33:%.*]] = zext i1 [[TMP49]] to i8
// CHECK-NEXT:    store i8 [[STOREDV33]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE24]]
// CHECK:       [[MONOTONIC_FAIL34]]:
// CHECK-NEXT:    [[TMP50:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP51:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP52:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP50]], i32 [[TMP51]] syncscope("workgroup-one-as") acq_rel monotonic, align 4
// CHECK-NEXT:    [[TMP53:%.*]] = extractvalue { i32, i1 } [[TMP52]], 0
// CHECK-NEXT:    [[TMP54:%.*]] = extractvalue { i32, i1 } [[TMP52]], 1
// CHECK-NEXT:    br i1 [[TMP54]], label %[[CMPXCHG_CONTINUE39:.*]], label %[[CMPXCHG_STORE_EXPECTED38:.*]]
// CHECK:       [[ACQUIRE_FAIL35]]:
// CHECK-NEXT:    [[TMP55:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP56:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP57:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP55]], i32 [[TMP56]] syncscope("workgroup-one-as") acq_rel acquire, align 4
// CHECK-NEXT:    [[TMP58:%.*]] = extractvalue { i32, i1 } [[TMP57]], 0
// CHECK-NEXT:    [[TMP59:%.*]] = extractvalue { i32, i1 } [[TMP57]], 1
// CHECK-NEXT:    br i1 [[TMP59]], label %[[CMPXCHG_CONTINUE42:.*]], label %[[CMPXCHG_STORE_EXPECTED41:.*]]
// CHECK:       [[SEQCST_FAIL36]]:
// CHECK-NEXT:    [[TMP60:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP61:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP62:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP60]], i32 [[TMP61]] syncscope("workgroup-one-as") acq_rel seq_cst, align 4
// CHECK-NEXT:    [[TMP63:%.*]] = extractvalue { i32, i1 } [[TMP62]], 0
// CHECK-NEXT:    [[TMP64:%.*]] = extractvalue { i32, i1 } [[TMP62]], 1
// CHECK-NEXT:    br i1 [[TMP64]], label %[[CMPXCHG_CONTINUE45:.*]], label %[[CMPXCHG_STORE_EXPECTED44:.*]]
// CHECK:       [[ATOMIC_CONTINUE37:.*]]:
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED38]]:
// CHECK-NEXT:    store i32 [[TMP53]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE39]]
// CHECK:       [[CMPXCHG_CONTINUE39]]:
// CHECK-NEXT:    [[STOREDV40:%.*]] = zext i1 [[TMP54]] to i8
// CHECK-NEXT:    store i8 [[STOREDV40]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE37]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED41]]:
// CHECK-NEXT:    store i32 [[TMP58]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE42]]
// CHECK:       [[CMPXCHG_CONTINUE42]]:
// CHECK-NEXT:    [[STOREDV43:%.*]] = zext i1 [[TMP59]] to i8
// CHECK-NEXT:    store i8 [[STOREDV43]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE37]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED44]]:
// CHECK-NEXT:    store i32 [[TMP63]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE45]]
// CHECK:       [[CMPXCHG_CONTINUE45]]:
// CHECK-NEXT:    [[STOREDV46:%.*]] = zext i1 [[TMP64]] to i8
// CHECK-NEXT:    store i8 [[STOREDV46]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE37]]
// CHECK:       [[MONOTONIC_FAIL47]]:
// CHECK-NEXT:    [[TMP65:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP66:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP67:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP65]], i32 [[TMP66]] syncscope("workgroup") seq_cst monotonic, align 4
// CHECK-NEXT:    [[TMP68:%.*]] = extractvalue { i32, i1 } [[TMP67]], 0
// CHECK-NEXT:    [[TMP69:%.*]] = extractvalue { i32, i1 } [[TMP67]], 1
// CHECK-NEXT:    br i1 [[TMP69]], label %[[CMPXCHG_CONTINUE52:.*]], label %[[CMPXCHG_STORE_EXPECTED51:.*]]
// CHECK:       [[ACQUIRE_FAIL48]]:
// CHECK-NEXT:    [[TMP70:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP71:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP72:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP70]], i32 [[TMP71]] syncscope("workgroup") seq_cst acquire, align 4
// CHECK-NEXT:    [[TMP73:%.*]] = extractvalue { i32, i1 } [[TMP72]], 0
// CHECK-NEXT:    [[TMP74:%.*]] = extractvalue { i32, i1 } [[TMP72]], 1
// CHECK-NEXT:    br i1 [[TMP74]], label %[[CMPXCHG_CONTINUE55:.*]], label %[[CMPXCHG_STORE_EXPECTED54:.*]]
// CHECK:       [[SEQCST_FAIL49]]:
// CHECK-NEXT:    [[TMP75:%.*]] = load i32, ptr [[TMP2]], align 4
// CHECK-NEXT:    [[TMP76:%.*]] = load i32, ptr [[DOTATOMICTMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP77:%.*]] = cmpxchg ptr [[TMP0]], i32 [[TMP75]], i32 [[TMP76]] syncscope("workgroup") seq_cst seq_cst, align 4
// CHECK-NEXT:    [[TMP78:%.*]] = extractvalue { i32, i1 } [[TMP77]], 0
// CHECK-NEXT:    [[TMP79:%.*]] = extractvalue { i32, i1 } [[TMP77]], 1
// CHECK-NEXT:    br i1 [[TMP79]], label %[[CMPXCHG_CONTINUE58:.*]], label %[[CMPXCHG_STORE_EXPECTED57:.*]]
// CHECK:       [[ATOMIC_CONTINUE50:.*]]:
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED51]]:
// CHECK-NEXT:    store i32 [[TMP68]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE52]]
// CHECK:       [[CMPXCHG_CONTINUE52]]:
// CHECK-NEXT:    [[STOREDV53:%.*]] = zext i1 [[TMP69]] to i8
// CHECK-NEXT:    store i8 [[STOREDV53]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE50]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED54]]:
// CHECK-NEXT:    store i32 [[TMP73]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE55]]
// CHECK:       [[CMPXCHG_CONTINUE55]]:
// CHECK-NEXT:    [[STOREDV56:%.*]] = zext i1 [[TMP74]] to i8
// CHECK-NEXT:    store i8 [[STOREDV56]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE50]]
// CHECK:       [[CMPXCHG_STORE_EXPECTED57]]:
// CHECK-NEXT:    store i32 [[TMP78]], ptr [[TMP2]], align 4
// CHECK-NEXT:    br label %[[CMPXCHG_CONTINUE58]]
// CHECK:       [[CMPXCHG_CONTINUE58]]:
// CHECK-NEXT:    [[STOREDV59:%.*]] = zext i1 [[TMP79]] to i8
// CHECK-NEXT:    store i8 [[STOREDV59]], ptr [[CMPXCHG_BOOL_ASCAST]], align 1
// CHECK-NEXT:    br label %[[ATOMIC_CONTINUE50]]
//
void generalFailureOrder(atomic_int *ptr, int *ptr2, int success, int fail) {
  __opencl_atomic_compare_exchange_strong(ptr, ptr2, 42, success, fail, memory_scope_work_group);




















}

// CHECK-LABEL: define dso_local i32 @test_volatile(
// CHECK-SAME: ptr noundef [[I:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[ATOMIC_TEMP:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[RETVAL_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[RETVAL]] to ptr
// CHECK-NEXT:    [[I_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[I_ADDR]] to ptr
// CHECK-NEXT:    [[ATOMIC_TEMP_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[ATOMIC_TEMP]] to ptr
// CHECK-NEXT:    store ptr [[I]], ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[I_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load atomic volatile i32, ptr [[TMP0]] syncscope("workgroup") seq_cst, align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[ATOMIC_TEMP_ASCAST]], align 4
// CHECK-NEXT:    ret i32 [[TMP2]]
//
int test_volatile(volatile atomic_int *i) {
  return __opencl_atomic_load(i, memory_order_seq_cst, memory_scope_work_group);
}

#endif
